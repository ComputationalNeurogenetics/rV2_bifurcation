---
title: "R Notebook of TOBIAS table operations"
output: html_document
---

```{r Packages, message=FALSE}
library(rtracklayer)
library(qs)
library(Seurat)
library(Signac)
library(tidyverse)
library(GenomicRanges)
library(parallel)
library(dbplyr)
library(DBI)
library(EnsDb.Mmusculus.v79)
library(hash)
library(ChIPpeakAnno)
cores<-10
source("~/Workspace/AuxCode/TOBIAS_tools.R")
source("~/Workspace/AuxCode/AuxFunctions.R")
library(rtracklayer)
library(plyranges)
library(data.table)
```

```{r Additional functions}
message_parallel <- function(...){
  system(sprintf('echo "\n%s\n"', paste0(..., collapse="")))
}
```

```{r Reading Seurat dataobject}
dataset <- qread("../serot/sero_relabeled_201123_links.qs", nthreads = cores)
DefaultAssay(dataset) <- "RNA"

DefaultAssay(dataset) <- "peaks"
all.features <- StringToGRanges(rownames(dataset))

gene_id2name <- hash(rownames(dataset[['RNA']][[]]),dataset[['RNA']][[]][,1])
gene_name2id <- hash(dataset[['RNA']][[]][,1],rownames(dataset[['RNA']][[]]))
```

```{r Reading Tobias results and H12 metadata, eval=TRUE}
#rV2.groups.tobias.h12.gr.dr <- qread("../analysis/rV2.groups.tobias.h12.gr.dr.regrouped.qs", nthreads = 8)

serot.groups.tobias.h12.gr.dr <- get_BINDetect_snakemake_results_gr(res_path="/Volumes/MyBookDuo/Data/TOBIAS_input_output/E12SR_280424/TFBS/",parallel=F, mc.cores=2, HOCOMOCO=12)

#H12.metadata <- qread(file="../analysis/H12_metadata_mod.qs")
#H12.metadata$TF.rep <- paste(H12.metadata$name,"_",H12.metadata$name,sep="")
#write_csv(H12.metadata, col_names = TRUE, file = "../metadata/H12.data.csv")
H12.metadata <- read_delim("../metadata/H12.data_INSM1_added.csv", col_names = TRUE, delim = ";")
```

```{r Transform tobias gr to tb, eval=TRUE}
tobias.tb.list <- lapply(serot.groups.tobias.h12.gr.dr, as_tibble)
tobias.tb <- do.call(rbind,tobias.tb.list)
tobias.tb$start <- tobias.tb$start+1
qsave(tobias.tb, file = "../analysis/Tobias.serot.h12.dr.tb.qs",nthreads = 10)
```

```{r Finding TFBS to feature matches, eval=TRUE}
TFBS.pos.tb <- tobias.tb %>% dplyr::select(seqnames, start, end, TFBS_name)
TFBS.to.features <- mergeByOverlaps(query = makeGRangesFromDataFrame(TFBS.pos.tb, keep.extra.columns = T), subject = all.features,type="within")

TFBS.to.features.tb <- cbind(as_tibble(TFBS.to.features$`makeGRangesFromDataFrame(TFBS.pos.tb, keep.extra.columns = T)`), features=GRangesToString(TFBS.to.features$all.features))
                             
tobias.tb.2 <- left_join(tobias.tb, dplyr::select(TFBS.to.features.tb, seqnames, start, end, TFBS_name, features))
rm(TFBS.to.features.tb)
rm(tobias.tb)
rm(rV2.groups.tobias.h12.gr.dr)
gc()

qsave(tobias.tb.2, file = "../analysis/Tobias.serot.h12.dr.tb.qs",nthreads = 10)
```

```{r Connection to SQLite}
dbname <- "~/Workspace/TOBIAS.serot.h12_230524.sqlite"
serot.con <- DBI::dbConnect(RSQLite::SQLite(), dbname = dbname)
```

```{r Write gene.metadata into SQlite}
gene.metadata <- dataset[['RNA']][[]] %>% rownames_to_column("ensg_id") %>% rename("gene_name"="feature_symbol")
dbWriteTable(serot.con, "gene_metadata", gene.metadata, overwrite=TRUE)
dbExecute(serot.con, 'CREATE INDEX ensg_id3 ON gene_metadata (ensg_id);')
dbExecute(serot.con, 'CREATE INDEX gene_name3 ON gene_metadata (gene_name);')
```

```{r Write features table into SQLite, eval=TRUE}
features.tb <- as_tibble(all.features)
features.tb$feature <- paste(features.tb$seqnames,"-",features.tb$start,"-",features.tb$end,sep="")

dbWriteTable(serot.con, "feature", features.tb, overwrite=TRUE)
dbExecute(serot.con, 'CREATE INDEX features2 ON feature (feature);')
dbExecute(serot.con, 'CREATE INDEX seqnames2 ON feature (seqnames);')
dbExecute(serot.con, 'CREATE INDEX start2 ON feature (start);')
dbExecute(serot.con, 'CREATE INDEX end2 ON feature (end);')
```

```{r Write TOBIAS data into SQlite, eval=TRUE}
dbWriteTable(serot.con, "tobias", tobias.tb.2, overwrite=TRUE)
dbListTables(serot.con)
rm(tobias.tb.2)
gc()
```

```{r Build indeces, eval=TRUE}
dbExecute(serot.con, 'CREATE INDEX seqname 
ON tobias (seqnames);')

dbExecute(serot.con, 'CREATE INDEX position 
ON tobias (seqnames, start, end);')

dbExecute(serot.con, 'CREATE INDEX TFBS_name 
ON tobias (TFBS_name);')

dbExecute(serot.con, 'CREATE INDEX features 
ON tobias (features);')
```

```{r Make gene name corrections}
tobias.tm <- dbGetQuery(serot.con, 'SELECT TFBS_name FROM tobias')

tobias.tm <- left_join(tobias.tm, dplyr::select(H12.metadata, TF.rep, masterlist_info.tf,ensg_id), by=c("TFBS_name"="TF.rep")) %>% distinct()
colnames(tobias.tm) <- c("TFBS_name","masterlist_info_tf","ensg_id")

dbWriteTable(serot.con, "gene_name_tmp", tobias.tm, overwrite=T)
dbExecute(serot.con, 'CREATE INDEX TFBS_name_2 
ON gene_name_tmp (TFBS_name);')

dbExecute(serot.con, 'ALTER TABLE tobias ADD COLUMN TF_gene_name TEXT;')
dbExecute(serot.con, 'ALTER TABLE tobias ADD COLUMN ensg_id TEXT;')

dbExecute(serot.con, '
UPDATE tobias
SET TF_gene_name = (
    SELECT masterlist_info_tf
    FROM gene_name_tmp
    WHERE gene_name_tmp.TFBS_name = tobias.TFBS_name
),
ensg_id = (
    SELECT ensg_id
    FROM gene_name_tmp
    WHERE gene_name_tmp.TFBS_name = tobias.TFBS_name
);
')

dbExecute(serot.con, 'DROP TABLE gene_name_tmp;')

dbExecute(serot.con, 'CREATE INDEX TF_gene_name ON tobias (TF_gene_name);')
dbExecute(serot.con, 'CREATE INDEX ensg_id ON tobias (ensg_id);')
gc()
```

```{r Calculate conservation scores as averages, eval=FALSE}
# Function to load conservation data one chromosome at a time to manage memory use
import_bw_chunk <- function(chromosome) {
  gr <- GRanges(seqnames = chromosome, ranges = IRanges(start = 1, end = seqlengths(BSgenome.Mmusculus.UCSC.mm10)[chromosome]))
  import(con = "../metadata/mm10.60way.phastCons.bw", which = gr)
}

# Read TFBS locations from the database
TFBS.loc <- dbGetQuery(serot.con, 'SELECT seqnames, start, end, TFBS_name FROM tobias WHERE seqnames IN ("chr1","chr2","chr3","chr4","chr5","chr6","chr7","chr8","chr9","chr10","chr11","chr12","chr13","chr14","chr15","chr16","chr17","chr18","chr19","chrX","chrY");')

# Use data.table for efficient data manipulation
TFBS.loc <- as.data.table(TFBS.loc)
uniq.seq.names <- unique(TFBS.loc$seqnames)

# Function to process each chromosome
process_chromosome <- function(seq.name) {
  message_parallel(paste("Processing", seq.name))
  gc()

  # Load conservation data for the chromosome
  cons.gr <- import_bw_chunk(seq.name)
  if (length(cons.gr) == 0) return(NULL)

  # Subset TFBS for the chromosome
  TFBS.tmp <- TFBS.loc[seqnames == seq.name]
  if (nrow(TFBS.tmp) == 0) return(NULL)

  TFBS.gr <- makeGRangesFromDataFrame(TFBS.tmp)

  # Find overlaps
  overlaps <- findOverlaps(query = cons.gr, subject = TFBS.gr, type = "within")

  # Merge overlaps and compute mean conservation score
  if (length(overlaps) == 0) return(NULL)

  cons.subset <- cons.gr[queryHits(overlaps)]
  TFBS.subset <- TFBS.gr[subjectHits(overlaps)]
  TFBS.subset$score <- cons.subset$score

  TFBS.cons.means <- as_tibble(TFBS.subset %>% plyranges::group_by(start, end) %>% summarize(mean.cons = mean(score)))
  TFBS.cons.means$seqnames <- seq.name

  return(TFBS.cons.means)
}

# Process each chromosome in parallel
TFBS.loc.cons.list <- mclapply(uniq.seq.names, process_chromosome, mc.cores = 2)

# Filter out NULL results
TFBS.loc.cons.list <- Filter(Negate(is.null), TFBS.loc.cons.list)

# Combine results into one table
TFBS.loc.cons.tb <- rbindlist(TFBS.loc.cons.list, fill = TRUE)
colnames(TFBS.loc.cons.tb) <- c("start", "end", "mean_cons", "seqnames")

# Merge results back to original TFBS locations
tobias.cons.tmp <- merge(TFBS.loc, TFBS.loc.cons.tb, by = c("seqnames", "start", "end"), all.x = TRUE)

# Write results back to the database
dbWriteTable(serot.con, "TFBS_pos_cons_tmp", tobias.cons.tmp, overwrite = TRUE)
dbExecute(serot.con, 'CREATE INDEX TFBS_loc_2 ON TFBS_pos_cons_tmp (seqnames, start, end);')
dbExecute(serot.con, 'ALTER TABLE tobias ADD COLUMN mean_cons REAL;')

dbExecute(serot.con, '
UPDATE tobias
SET mean_cons = (
    SELECT mean_cons
    FROM TFBS_pos_cons_tmp
    WHERE TFBS_pos_cons_tmp.seqnames = tobias.seqnames AND TFBS_pos_cons_tmp.start = tobias.start AND TFBS_pos_cons_tmp.end = tobias.end
)')

dbExecute(serot.con, 'DROP TABLE TFBS_pos_cons_tmp;')

# Cleanup
gc()
```

```{r}
parse_meme_file <- function(file_path) {
  # Read the file content
  lines <- readLines(file_path)
  
  # Initialize variables
  motifs <- list()
  motif_name <- NULL
  matrix_start <- FALSE
  matrix_data <- NULL
  
  # Loop through each line to parse motifs and matrices
  for (line in lines) {
    if (startsWith(line, "MOTIF")) {
      # Save the previous matrix if we were reading one
      if (!is.null(motif_name) && !is.null(matrix_data)) {
        motifs[[motif_name]] <- matrix(matrix_data, ncol = ncol(matrix_data), byrow = TRUE)
      }
      # Start a new motif
      motif_name <- strsplit(line, " ")[[1]][2]
      matrix_data <- NULL
    } else if (startsWith(line, "letter-probability matrix")) {
      matrix_start <- TRUE
      next
    } else if (matrix_start) {
      if (line == "") {
        matrix_start <- FALSE
      } else {
        # Convert line to numeric and check if valid
        numeric_line <- as.numeric(unlist(strsplit(line, "\\s+")))
        if (all(!is.na(numeric_line))) {
          # Append the line to the matrix data
          matrix_data <- rbind(matrix_data, numeric_line)
        }
      }
    }
  }
  
  # Save the last matrix
  if (!is.null(motif_name) && !is.null(matrix_data)) {
    motifs[[motif_name]] <- matrix(matrix_data, ncol = ncol(matrix_data), byrow = TRUE)
  }
  
  return(motifs)
}

# Example usage
file_path <- "../mm10/Hocomoco.v12/H12CORE_meme_format.meme"
motifs.h12 <- parse_meme_file(file_path)

# Example usage
file_path.h11 <- "../mm10/Hocomoco.v11/HOCOMOCOv11_core_MOUSE_mono_meme_format.meme"
motifs.h11 <- parse_meme_file(file_path.h11)

motifs.h12[["INSM1_MOUSE.H11MO.0.C"]] <- motifs.h11[["INSM1_MOUSE.H11MO.0.C"]]

# Print the list of motifs and their matrices
tail(motifs.h12)

positional.mean.weights <- lapply(motifs.h12,rowMax)
names(positional.mean.weights) <- paste(names(positional.mean.weights),names(positional.mean.weights),sep="_")

```

```{r, eval=TRUE}
# Define a function to calculate the weighted mean for each group
calculate_weighted_mean <- function(data,positional.mean.weights) {
  TFBS_name <- unique(data$TFBS_name)
  if (length(TFBS_name) != 1) {
    stop("Each group should have exactly one TFB_name.")
  }
  weights <- positional.mean.weights[[TFBS_name]]
  if (is.null(weights)) {
    stop(paste("No weights found for TFB_name:", TFBS_name))
  }
  if (length(weights) != nrow(data)) {
    # Store information about the problematic group
    # Return NA
    mean.cons <- NA
  } else {
    # Calculate weighted mean
    mean.cons <- weighted.mean(data$score, weights)
  }
  tibble(start = unique(data$start), end = unique(data$end), TFBS_name = TFBS_name, mean.cons = mean.cons)
}
uniq.seq.names <- unique(pull(TFBS.loc,seqnames))

TFBS.loc.cons.list <- mclapply(uniq.seq.names, function(seq.name){
  message_parallel(paste("Processing",seq.name,sep=" "))
  gc()
  TFBS.tmp <- makeGRangesFromDataFrame(dplyr::filter(TFBS.loc, seqnames==seq.name), keep.extra.columns = T)
  cons.subset <- import_bw_chunk(seq.name)

  # Split TFBS.tmp into single-base intervals
  TFBS.tmp.split <- unlist(tile(TFBS.tmp, width=1))

  # Replicate metadata to each single-base interval
  metadata <- as.data.frame(mcols(TFBS.tmp))
  metadata_rep <- metadata[rep(1:nrow(metadata), lengths(tile(TFBS.tmp, width=1))), ]
  mcols(TFBS.tmp.split) <- metadata_rep

  # Find overlaps between single-base intervals and cons.subset
  overlaps <- findOverlaps(query = cons.subset, subject = TFBS.tmp.split)

  # Create a data frame from TFBS.tmp.split
  TFBS.df <- as.data.frame(TFBS.tmp.split)
  colnames(TFBS.df)[colnames(TFBS.df) == "X"] <- "TFBS_name"

  # Initialize the score column with NA
  TFBS.df$score <- NA

  # Get the indices of the overlapping regions
  query_hits <- queryHits(overlaps)
  subject_hits <- subjectHits(overlaps)

  # Copy the score from cons.subset to TFBS.df
  TFBS.df$score[subject_hits] <- mcols(cons.subset)$score[query_hits]

  # Create a grouping variable to identify consecutive ranges
  TFBS.df <- TFBS.df %>%
  arrange(TFBS_name, start, end) %>%
  mutate(group = cumsum(c(1, diff(start) != 1 | diff(as.numeric(factor(TFBS_name))) != 0)))

# TFBS.df <- TFBS.df %>%
#   arrange(TFBS_name, start) %>%
#   dplyr::select(-is_consecutive)

# TFBS.df <- TFBS.df %>%
#   arrange(TFBS_name, start) %>%
#   mutate(is_consecutive = (start == dplyr::lag(end, default = dplyr::first(start))) & (TFBS_name == dplyr::lag(TFBS_name, default = dplyr::first(TFBS_name))), group = cumsum(!is_consecutive)) %>%
#   dplyr::select(-is_consecutive)

  # Update each row within the group to have the smallest start and largest end
  TFBS.df <- TFBS.df %>%
  group_by(group, TFBS_name) %>%
  mutate(start = min(start), end = max(end)) %>%
  ungroup() %>%
  dplyr::select(-group)  # Remove the temporary group column

  TFBS.cons.means <- TFBS.df %>% group_by(start,end,TFBS_name) %>% group_split() %>%
  map_dfr(~ calculate_weighted_mean(.x,positional.mean.weights=positional.mean.weights))
  TFBS.cons.means$seqnames <-seq.name
  return(TFBS.cons.means)
}, mc.cores = 2)

TFBS.loc.cons.tb <- do.call(rbind,TFBS.loc.cons.list)
colnames(TFBS.loc.cons.tb) <- c("start","end","TFBS_name","w.mean_cons","seqnames")
tobias.cons.tmp <- left_join(TFBS.loc, TFBS.loc.cons.tb, by=c("seqnames","start","end","TFBS_name"))

tobias.cons.tmp <- rename(tobias.cons.tmp, "w_mean_cons"="w.mean_cons")

dbWriteTable(serot.con, "TFBS_pos_cons_tmp", tobias.cons.tmp, overwrite=TRUE)
dbExecute(serot.con, 'CREATE INDEX TFBS_loc_2_2
ON TFBS_pos_cons_tmp (seqnames, start, end);')

dbExecute(serot.con, 'ALTER TABLE tobias ADD COLUMN w_mean_cons REAL;')

dbExecute(serot.con, '
UPDATE tobias
SET w_mean_cons = (
    SELECT w_mean_cons
    FROM TFBS_pos_cons_tmp
    WHERE TFBS_pos_cons_tmp.seqnames = tobias.seqnames AND TFBS_pos_cons_tmp.start = tobias.start AND TFBS_pos_cons_tmp.end = tobias.end
)')

dbExecute(serot.con, 'DROP TABLE TFBS_pos_cons_tmp;')
```


# Calculate expression and accessibility information into the database

```{r Calculate and upload average gene expression data per cell group into separate table}
ensg_ids <- dbGetQuery(serot.con, 'SELECT DISTINCT ensg_id FROM tobias;')[,1]

TF.expression.data.avg2 <- AverageExpression(dataset, assays = "RNA", features = ensg_ids, group.by = "sero.lineage", layer = "data")[[1]]

dbWriteTable(serot.con, "exp", as.data.frame(TF.expression.data.avg2) %>% rownames_to_column("ensg_id") %>% as_tibble(), overwrite=TRUE)

dbExecute(serot.con, 'CREATE INDEX ensg_ids_2 ON exp (ensg_id);')
```

```{r Calculate and upload z-score normalized gene expression averages per TF gene per cell group into separate table}
ensg_ids <- dbGetQuery(serot.con, 'SELECT DISTINCT ensg_id FROM tobias;')[,1]

DefaultAssay(dataset) <- "RNA"
TF.expression.data <- FetchData(object=dataset, assays = "RNA", vars = c(ensg_ids,"sero.lineage"))
TF.expression.data.mat <- as.matrix(expm1(as_tibble(TF.expression.data) %>% dplyr::select(!starts_with("sero"))))
TF.expression.data.mat <- as_tibble(t(scale(t(TF.expression.data.mat))))
TF.expression.data.mat$sero.lineage <- TF.expression.data$sero.lineage
TF.expression.data.mat <- pivot_longer(TF.expression.data.mat, cols = !starts_with("sero"))

TF.expr.scaled <- TF.expression.data.mat %>% group_by(sero.lineage, name) %>% summarise(avg.exp=mean(value,na.rm=T)) %>% pivot_wider(values_from = avg.exp, names_from = sero.lineage)

names(TF.expr.scaled)[1] <- "ensg_id"

dbWriteTable(serot.con, "exp_scaled", TF.expr.scaled, overwrite=TRUE)

dbExecute(serot.con, 'CREATE INDEX ensg_ids_3 ON exp_scaled (ensg_id);')
```

```{r Calculate and upload feature accessibility data per feature per cell group into separate table }
features <- dbGetQuery(serot.con, 'SELECT DISTINCT features FROM tobias;')[,1]

acc.avg.data <- AverageExpression(dataset, assays = "peaks", features = features, group.by = "sero.lineage")[[1]]

dbWriteTable(serot.con, "acc", as.data.frame(acc.avg.data) %>% rownames_to_column("features") %>% as_tibble(), overwrite=TRUE)

dbExecute(serot.con, 'CREATE INDEX features_2 ON acc (features);')
```

```{r Additional corrections to TF_gene_name field}
dbExecute(serot.con, "UPDATE tobias
SET TF_gene_name = 'NGN1'
WHERE TF_gene_name LIKE '1,0%NGN';")

dbExecute(serot.con, "UPDATE tobias
SET TF_gene_name = 'NGN2'
WHERE TF_gene_name LIKE '2,0%NGN';")

dbExecute(serot.con, "UPDATE tobias
SET TF_gene_name = 'MAD4'
WHERE TF_gene_name LIKE '4,0%MAD';")
```

```{r}
DefaultAssay(dataset) <- "peaks"
Links(dataset) <- GenomicRanges::GRanges()

mm10.v79.genome.GR <- toGRanges(
  EnsDb.Mmusculus.v79,
  feature = c("gene", "transcript", "exon", "disjointExons")
)
mm10.v79.genome.GR$gene_id <- names(mm10.v79.genome.GR)
DefaultAssay(dataset) <- "RNA"

gene_ids <- unique(intersect(names(mm10.v79.genome.GR), rownames(dataset)))

# Read TAD map
TAD.map <- read_table("../metadata/cb.csail.mit.edu_cb_tadmap_TADMap_scaffold_mm.bed.txt", col_names = c("seqnames", "start", "end")) %>% GRanges()

# Open database connection
#con.obj <- DBI::dbConnect(RSQLite::SQLite(), dbname = "~/Workspace/TOBIAS.dr.h12_140524.sqlite")
#dbExecute(serot.con, 'DROP TABLE links;')

# Function to process each gene ID
process_gene_id <- function(i) {
  idx <- gene_ids[i]
  message_parallel(paste(i,"/",length(gene_ids),sep=""))
  
  # Find the TAD for the gene in question
  gene.range <- mm10.v79.genome.GR[which(names(mm10.v79.genome.GR) == idx)]
  TAD.overlap <- plyranges::filter_by_overlaps(TAD.map, gene.range)
  
  tryCatch({
    Link.Seurat <- LinkPeaks(
      object = dataset, peak.assay = "peaks", expression.assay = "RNA",
      genes.use = idx, gene.id = TRUE, distance = width(TAD.overlap),
      gene.coords = mm10.v79.genome.GR, peak.slot = "counts",
      expression.slot = "data", method = "pearson"
    )
    
  links.tb <- as_tibble(Link.Seurat@assays$peaks@links) %>% rename("feature"="peak") %>% rename("ensg_id"="gene")
    
    success <- FALSE
    con.obj <- DBI::dbConnect(RSQLite::SQLite(), dbname = dbname)
    while (!success) {
      tryCatch({
        dbWriteTable(con.obj, "links", links.tb, overwrite = FALSE, append = TRUE)
        success <- TRUE
      }, error = function(e) {
        Sys.sleep(0.25)
      })
    }
  }, error = function(e) {
    cat("An error occurred:", e$message, "\n")
  }, warning = function(w) {
    cat("A warning occurred:", w$message, "\n")
  })
  DBI::dbDisconnect(con.obj)
}

# Process gene IDs in parallel
mclapply(1:length(gene_ids), process_gene_id, mc.cores = 3)

# Close the database connection
#DBI::dbDisconnect(con.obj)

# Cleanup
#rm(TFBS.to.features.tb)
#rm(tobias.tb)
#gc()

dbExecute(serot.con, 'CREATE INDEX ensg_id5 ON links (ensg_id);')
dbExecute(serot.con, 'CREATE INDEX feature4 ON links (feature);')
dbExecute(serot.con, 'CREATE INDEX zscore1 ON links (zscore);')
dbExecute(serot.con, 'CREATE INDEX links_pvalue ON links (pvalue);')
```

```{r Calculating LinkPeaks within TADs}
mm10.v79.genome.GR <- toGRanges(
  EnsDb.Mmusculus.v79,
  feature = c("gene", "transcript", "exon", "disjointExons")
)

mm10.v79.genome.GR$gene_id <- names(mm10.v79.genome.GR)

DefaultAssay(dataset) <- "RNA"

gene_ids <- unique(intersect(names(mm10.v79.genome.GR),rownames(dataset)))

#the information about TAD areas - https://cb.csail.mit.edu/cb/tadmap/
TAD.map <- read_table("../metadata/cb.csail.mit.edu_cb_tadmap_TADMap_scaffold_mm.bed.txt", col_names = c("seqnames", "start", "end"))%>% 
  GRanges()

#Function
links.within.TADs <- mclapply(gene_ids, function(idx){

  con.obj <- DBI::dbConnect(RSQLite::SQLite(), dbname = dbname)
  #first we find the TAD - topologically associated domain - for each of the marker genes
  gene.range <- mm10.v79.genome.GR[which(names(mm10.v79.genome.GR) == idx)]

  TAD.overlap <-plyranges::filter_by_overlaps(TAD.map,gene.range)
  tryCatch({
    Link.Seurat <- LinkPeaks(object = dataset, peak.assay = "peaks", expression.assay = "RNA",genes.use = idx, gene.id = T, distance = width(TAD.overlap), gene.coords = mm10.v79.genome.GR,  peak.slot = "counts", expression.slot = "data", method = "spearman")
  
    links.tb <- as_tibble(Link.Seurat@assays$peaks@links) %>% rename("peak"="feature") %>% rename("gene"="ensg_id")
      success <- FALSE
    while(!success & base::exists("links.tb")) {
      tryCatch({
        dbWriteTable(con.obj, "links_s", links.tb, overwrite=FALSE, append=TRUE)
        success <- TRUE # If dbWriteTable succeeds, set success to TRUE
      }, error = function(e) {
        Sys.sleep(0.25) # Wait for 1 seconds before retrying
      })
    }
    },
  error = function(e) {
    cat("An error occurred:", e$message, "\n")
    },
  warning = function(w) {
    cat("A warning occurred:", w$message, "\n")
  })
  # Handle warning if necessary)
  DBI::dbDisconnect(con.obj)
  #return(links)
}, mc.cores = cores)

dbExecute(serot.con, 'CREATE INDEX ensg_id5 ON links_s (ensg_id);')
dbExecute(serot.con, 'CREATE INDEX feature4 ON links_s (feature);')
dbExecute(serot.con, 'CREATE INDEX zscore1 ON links_s (zscore);')
dbExecute(serot.con, 'CREATE INDEX links_pvalue ON links_s (pvalue);')
```

```{r C&T data import}
consensus.beds.path <- list.files(path="/Volumes/MyBookDuo/Data/Cut_Tag/out_030524/03_peak_calling/05_consensus_peaks/", pattern = "*.awk.bed", full.names = T)

consensus.beds <- lapply(consensus.beds.path, function(path){
  tmp.1 <- read_delim(file = path, col_names = c("chr","start","end","start_merged","end_merged","total_signals","max_signals","max_signal_regions","sample_names","consensus_replicate_count"))
  if (nrow(tmp.1)>0){
  tmp.1$target_gene_name <- str_extract(string=tmp.1$sample_names, pattern = "(?<=_)[^_]+(?=_)")
  return(tmp.1)
  } else {
    return(NA)
  }
  })

consensus.beds.tb <- do.call(rbind,consensus.beds)
consensus.beds.tb <- consensus.beds.tb %>% mutate(row_id = row_number()) 

# Normalize the data (in SQL sense)
normalized_data <- consensus.beds.tb %>%
  # Create an index to keep track of the original row positions
  # Expand the rows based on the comma-separated values
  separate_rows(total_signals, max_signals, max_signal_regions,sample_names, sep = ",") %>%
  # Group by the original row index to ensure correct order
  group_by(row_id) %>%
  # Create a new ID to ensure uniqueness
  mutate(normalized_id = row_number()) %>%
  ungroup()

normalized_data<-normalized_data[!is.na(normalized_data$chr),]
normalized_data$start <- normalized_data$start+1
```

```{r}
ct.gr <- makeGRangesFromDataFrame(normalized_data,na.rm=T, keep.extra.columns = T)
feat.gr <- all.features

# Assuming ct.gr and feat.gr are already defined GRanges objects
# Find overlaps
overlaps <- findOverlaps(ct.gr, feat.gr)

# Assuming 'A' is your original tibble that corresponds to ct.gr
# Let's add an identifier to 'A' for the linkage
normalized_data <- normalized_data %>% mutate(row_id = row_number())

# Extract overlapping information with a new 'feature' column that combines 'chr', 'start', 'end'
overlap_info <- tibble(
  row_id = queryHits(overlaps),
  feature = paste(seqnames(feat.gr)[subjectHits(overlaps)], 
                  start(feat.gr)[subjectHits(overlaps)], 
                  end(feat.gr)[subjectHits(overlaps)], 
                  sep = "-")
)

normalized_data_expanded <- normalized_data %>%
  right_join(overlap_info, by = "row_id")

normalized_data_expanded <- normalized_data_expanded %>% mutate(start=as.integer(start), end=as.integer(end), total_signals=as.numeric(total_signals), max_signals=as.numeric(max_signals), consensus_replicate_count=as.integer(consensus_replicate_count))

```

```{r}
dbWriteTable(serot.con, "CT_data", normalized_data_expanded, overwrite=TRUE)
dbExecute(serot.con, 'CREATE INDEX CT_data_feature ON CT_data (feature);')
dbExecute(serot.con, 'CREATE INDEX CT_data_max_signals ON CT_data (max_signals);')
dbExecute(serot.con, 'CREATE INDEX CT_data_target_gene_name ON CT_data (target_gene_name);')
```

# Misc

```{r Feature to gene correlation, eval=FALSE}
DefaultAssay(dataset) <- "peaks"
acc.data.matrix <- FetchData(dataset, vars = rownames(dataset))
zero.test <- apply(acc.data.matrix,2,function(col){!all(col==0)})
acc.data.matrix<- acc.data.matrix[,zero.test]
DefaultAssay(dataset) <- "RNA"

TF_ensg_ids <- unique(dbGetQuery(con, 'SELECT ensg_id FROM tobias;')[,1])
DBI::dbDisconnect(con)

mclapply(TF_ensg_ids, function(ensg_id){
  tryCatch({
    exp.data.matrix <- FetchData(dataset, vars = ensg_id)
    if (!all(exp.data.matrix[,1]==0)){
    #message_parallel(paste("Calculating gene ",ensg_id))
    test.res <- na.omit(cor(exp.data.matrix,acc.data.matrix, method = "spearman", use="pairwise.complete.obs"))
    data.to.db <- tibble(ensg_id=rownames(test.res),feature=colnames(test.res),cor=test.res[1,])
    
    success <- FALSE
    con.obj <- DBI::dbConnect(RSQLite::SQLite(), dbname = dbname)
    while(!success) {
      tryCatch({
        success <- dbWriteTable(con.obj, "gene2feat_cor", data.to.db, overwrite=FALSE, append=TRUE)
        DBI::dbDisconnect(con.obj)
      }, error = function(e) {
        Sys.sleep(0.25)
      }, warning = function(e) {
        e
      })
    }
    }
    
    
  }, error=function(cond){
    cond
  },warning=function(cond){
    cond
  })
  
},mc.cores=3)
dbExecute(serot.con, 'CREATE INDEX gene2feat_cor_ensg_id ON gene2feat_cor (ensg_id);')
dbExecute(serot.con, 'CREATE INDEX gene2feat_cor_cor ON gene2feat_cor (cor);')
dbExecute(serot.con, 'CREATE INDEX gene2feat_cor_feature ON gene2feat_cor (feature);')
```


```{r Finding consequent motif areas, eval=FALSE}
tobias.table <- tbl(serot.con, "tobias")
exp.table <- tbl(serot.con, "exp")
acc.table <- tbl(serot.con, "acc")
table.tmp.1 <- tobias.table %>% left_join(exp.table) %>% left_join(acc.table, by=c("features"="features")) %>% dplyr::filter(mean_cons>0.5)
table.tmp.2 <- table.tmp.1 %>% collect()

acc.thr <- quantile(acc.table %>% dplyr::select(!starts_with("features")) %>% pull(),.25)
mean_cons_thr<-0.5

table.tmp.2 <- table.tmp.2 %>% dplyr::filter((abs(PRO1_2.x)>1.2 | abs(CO1_2.x)>1.2 | abs(GA1_2.x)>1.2 | abs(GL1_2.x)>1.2) & (abs(PRO1_2.y)>acc.thr | abs(CO1_2.y)>acc.thr | abs(GA1_2.y)>acc.thr | abs(GL1_2.y)>acc.thr) & (PRO1_2_bound==1 | CO1_2_bound==1 | GA1_2_bound==1 | GL1_2_bound==1) & mean_cons>mean_cons_thr) %>% arrange(start)

grB <- makeGRangesFromDataFrame(dplyr::select(table.tmp.2, seqnames, start, end, TFBS_name), keep.extra.columns = T)

reduced_grB_with_map <- reduce(grB, min.gapwidth=0L,with.revmap = TRUE)


# Step 2: Concatenate metadata based on the revmap information
concatenated_metadata <- mclapply(reduced_grB_with_map$revmap, function(indices) {
  if (length(indices) > 0) {
    meta_values <- mcols(grB)[indices, ]
    paste(unique(na.omit(meta_values)), collapse = "; ")
  } else {
    ""
  }
}, mc.cores = 10)

mcols(reduced_grB_with_map)$concatenated_metadata <- concatenated_metadata

plyranges::filter_by_overlaps(reduced_grB_with_map,StringToGRanges("chr4-114432894-115134633"))
mcols(plyranges::filter_by_overlaps(reduced_grB_with_map,StringToGRanges("chr4-114432894-115134633")))$concatenated_metadata

saveRDS(reduced_grB_with_map,"../analysis/TFBS_reduced_positions_120324.Rds")
```

```{r Calculating TFBS binding probability background, eval=FALSE}
genes_TF_count <- dbGetQuery(serot.con, 'SELECT li.ensg_id,
       tb.TF_gene_name,
       COUNT(tb.TF_gene_name) AS count
FROM links AS li
JOIN tobias AS tb ON tb.features = li.feature
WHERE li.zscore > 2 AND tb.mean_cons>0.5
GROUP BY li.ensg_id, tb.TF_gene_name;')
```


