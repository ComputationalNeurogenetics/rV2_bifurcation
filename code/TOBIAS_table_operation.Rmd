---
title: "R Notebook of TOBIAS table operations"
output: html_document
---

```{r Packages, message=FALSE}
library(rtracklayer)
library(qs)
library(Seurat)
library(Signac)
library(tidyverse)
library(GenomicRanges)
library(parallel)
library(dbplyr)
library(DBI)
library(hash)
library(EnsDb.Mmusculus.v79)
library(BSgenome.Mmusculus.UCSC.mm10)
library(ChIPpeakAnno)
cores <-10
source("local_settings.R")
library(plyranges)
library(data.table)
```

```{r Additional functions}
message_parallel <- function(...){
  system(sprintf('echo "\n%s\n"', paste0(..., collapse="")))
}
```

```{r Reading Seurat dataobject}
dataset <- qread("../scATAC_data/nmm_rV2_subset_relabeled_031023_links.qs", nthreads = cores)
DefaultAssay(dataset) <- "RNA"

dataset$rv2.lineage_re <- case_when(
  dataset$rv2.lineage %in% "PRO1" ~ "PRO1_2",
  dataset$rv2.lineage %in% "PRO2" ~ "PRO1_2",
  dataset$rv2.lineage %in% "GA1" ~ "GA1_2",
  dataset$rv2.lineage %in% "GA2" ~ "GA1_2",
  dataset$rv2.lineage %in% "GA3" ~ "GA3_4",
  dataset$rv2.lineage %in% "GA4" ~ "GA3_4",
  dataset$rv2.lineage %in% "GA5" ~ "GA5_6",
  dataset$rv2.lineage %in% "GA6" ~ "GA5_6",
  dataset$rv2.lineage %in% "CO1" ~ "CO1_2",
  dataset$rv2.lineage %in% "CO2" ~ "CO1_2",
  dataset$rv2.lineage %in% "GL1" ~ "GL1_2",
  dataset$rv2.lineage %in% "GL2" ~ "GL1_2",
  dataset$rv2.lineage %in% "GL3" ~ "GL3_4",
  dataset$rv2.lineage %in% "GL4" ~ "GL3_4",
  dataset$rv2.lineage %in% "GL5" ~ "GL5",
)

DefaultAssay(dataset) <- "peaks"
all.features <- StringToGRanges(rownames(dataset))

gene_id2name <- hash(rownames(dataset[['RNA']][[]]),dataset[['RNA']][[]][,1])
gene_name2id <- hash(dataset[['RNA']][[]][,1],rownames(dataset[['RNA']][[]]))
```

```{r Reading Tobias results and H12 metadata, eval=TRUE}
rV2.groups.tobias.h12.gr.dr <- get_BINDetect_snakemake_results(res_path="/Volumes/MyBookDuo/Data/TOBIAS_input_output/E12rV2_090224/TFBS/",parallel=T, HOCOMOCO=12,mc.cores = 10)

#H12.metadata <- qread(file="../analysis/H12_metadata_mod.qs")
#H12.metadata$TF.rep <- paste(H12.metadata$name,"_",H12.metadata$name,sep="")
#write_csv(H12.metadata, col_names = TRUE, file = "../metadata/H12.data.csv")
H12.metadata <- read_delim("../metadata/H12.data_INSM1_added.csv", col_names = TRUE, delim = ";")
```

```{r TRansform tobias gr to tb, eval=FALSE}
tobias.tb.list <- lapply(rV2.groups.tobias.h12.gr.dr, as_tibble)
tobias.tb <- do.call(rbind,tobias.tb.list)
tobias.tb$start <- tobias.tb$start+1 
qsave(tobias.tb, file = "../analysis/Tobias.rv2.h12.dr.tb_140524.qs",nthreads = cores)
rm(rV2.groups.tobias.h12.gr.dr)
gc()
```

```{r}
tobias.tb <- qread(file = "../analysis/Tobias.rv2.h12.dr.tb_140524.qs",nthreads = cores)
```

```{r}
# Select relevant columns
TFBS.pos.tb <- tobias.tb %>% dplyr::select(seqnames, start, end, TFBS_name)

# Create GRanges object from selected columns
TFBS.gr <- makeGRangesFromDataFrame(TFBS.pos.tb, keep.extra.columns = TRUE)

# Perform overlap merge
TFBS.to.features <- findOverlaps(TFBS.gr, all.features, type = "within")

# Extract matched ranges
query_hits <- queryHits(TFBS.to.features)
subject_hits <- subjectHits(TFBS.to.features)

# Convert to tibble and merge
TFBS.to.features.tb <- as_tibble(TFBS.gr[query_hits]) %>%
  mutate(features = GRangesToString(all.features[subject_hits]))

# Join the results back to the original tibble
tobias.tb.2 <- left_join(tobias.tb, TFBS.to.features.tb, by = c("seqnames", "start", "end", "TFBS_name"))

# Clean up
rm(TFBS.to.features.tb)
rm(tobias.tb)
gc()

qsave(tobias.tb.2, file = "../analysis/Tobias.rv2.h12.dr.tb_140524.2.qs",nthreads = cores)
```

```{r Finding TFBS to feature matches, eval=FALSE}
# TFBS.pos.tb <- tobias.tb %>% select(seqnames, start, end, TFBS_name)
# TFBS.to.features <- mergeByOverlaps(query = makeGRangesFromDataFrame(TFBS.pos.tb, keep.extra.columns = T), subject = all.features,type="within")
# 
# TFBS.to.features.tb <- cbind(as_tibble(TFBS.to.features$`makeGRangesFromDataFrame(TFBS.pos.tb, keep.extra.columns = T)`), features=GRangesToString(TFBS.to.features$all.features))
#                              
# tobias.tb.2 <- left_join(tobias.tb, select(TFBS.to.features.tb, seqnames, start, end, TFBS_name, features))
# rm(TFBS.to.features.tb)
# rm(tobias.tb)
# 
# qsave(tobias.tb.2, file = "../analysis/Tobias.rv2.h12.dr.tb_140524.2.qs",nthreads = cores)
```

```{r Connection to SQLite}
con.obj <- DBI::dbConnect(RSQLite::SQLite(), dbname = paste(db.path,dbname.rV2,sep=""))
con <- con.obj
```

```{r Write gene.metadata into SQlite}
# Extract metadata and TSS positions
gene.metadata <- dataset[['RNA']][[]] %>%
  rownames_to_column("ensg_id") %>%
  plotly::rename("gene_name" = "feature_symbol")

TSS.positions <- GetTSSPositions(Annotation(dataset)) %>%
  as_tibble()

# Gene positions with simplified calculations
gene_positions <- as_tibble(Annotation(dataset)) %>%
  select(seqnames, start, end, strand, gene_id) %>%
  mutate(
    start = as.numeric(start),
    end = as.numeric(end),
    seqnames = as.character(seqnames),
    strand=as.character(strand)
  ) %>%
  group_by(gene_id, strand) %>%
  summarise(
    seqnames = dplyr::first(seqnames),
    gene_start = if_else(dplyr::first(strand) == "-", max(end, na.rm = TRUE), min(start, na.rm = TRUE)),
    gene_end = if_else(dplyr::first(strand) == "-", min(start, na.rm = TRUE), max(end, na.rm = TRUE)),
    .groups = "drop"
  )

# Combine TSS positions into the gene metadata
gene.metadata <- gene.metadata %>%
  left_join(
    TSS.positions %>% select(seqnames, start, strand, gene_id),
    by = c("ensg_id" = "gene_id")
  ) %>%
  plotly::rename("TSS_start" = "start") %>%
  left_join(
    gene_positions %>% select(gene_id, gene_start, gene_end),
    by = c("ensg_id" = "gene_id")
  ) %>% distinct()

# Write the final gene metadata table to SQLite
dbWriteTable(con.obj, "gene_metadata", gene.metadata, overwrite = TRUE)
dbExecute(con.obj, 'CREATE INDEX ensg_id3 ON gene_metadata (ensg_id);')
dbExecute(con.obj, 'CREATE INDEX gene_name3 ON gene_metadata (gene_name);')
```

```{r Write features table into SQLite, eval=FALSE}
features.tb <- as_tibble(all.features)
features.tb$feature <- paste(features.tb$seqnames,"-",features.tb$start,"-",features.tb$end,sep="")

dbWriteTable(con.obj, "feature", features.tb, overwrite=TRUE)
dbExecute(con.obj, 'CREATE INDEX features2 ON feature (feature);')
dbExecute(con.obj, 'CREATE INDEX seqnames2 ON feature (seqnames);')
dbExecute(con.obj, 'CREATE INDEX start2 ON feature (start);')
dbExecute(con.obj, 'CREATE INDEX end2 ON feature (end);')

# Step 1: Add a new column to the 'feature' table
dbExecute(con.obj, "ALTER TABLE feature ADD COLUMN feature_name TEXT;")

# Step 2: Update the 'feature' table with the calculated feature names
# Since SQLite has limitations with complex updates involving joins and subqueries,
# we'll perform the calculations in R and then update the database.

# Fetch 'gene_metadata' table
gene_metadata_df <- dbGetQuery(con, "
  SELECT ensg_id, gene_name, seqnames, TSS_start, strand FROM gene_metadata;
")

# Check for NAs in TSS_start
num_na_tss <- sum(is.na(gene_metadata_df$TSS_start))
cat("Number of NAs in TSS_start:", num_na_tss, "\n")

if (num_na_tss > 0) {
  # Remove rows with NA in TSS_start
  gene_metadata_df <- gene_metadata_df[!is.na(gene_metadata_df$TSS_start), ]
  cat("Removed rows with NA in TSS_start.\n")
}

# Create a GRanges object for genes
gene_gr <- GRanges(
  seqnames = gene_metadata_df$seqnames,
  ranges = IRanges(
    start = gene_metadata_df$TSS_start,
    end = gene_metadata_df$TSS_start
  ),
  gene_name = gene_metadata_df$gene_name,
  strand = gene_metadata_df$strand
)

# Get the list of chromosomes to process
chromosomes <- unique(gene_metadata_df$seqnames)

# Process features chromosome by chromosome
for (chr in chromosomes) {
  message("Processing chromosome ", chr)
  
  # Fetch features for this chromosome
  feature_df <- dbGetQuery(con, paste0("
    SELECT rowid, seqnames, start, end FROM feature WHERE seqnames = '", chr, "';
  "))
  
  if (nrow(feature_df) == 0) {
    next  # Skip if no features on this chromosome
  }
  
  # Create a GRanges object for features
  feature_gr <- GRanges(
    seqnames = feature_df$seqnames,
    ranges = IRanges(start = feature_df$start, end = feature_df$end),
    rowid = feature_df$rowid
  )
  
  # Subset genes to this chromosome
  gene_gr_chr <- gene_gr[seqnames(gene_gr) == chr]
  
  if (length(gene_gr_chr) == 0) {
    next  # Skip if no genes on this chromosome
  }
  
  # Find the nearest gene for each feature
  nearest_genes <- nearest(feature_gr, gene_gr_chr, select = "arbitrary")
  
  # Handle cases where no nearest gene is found
  valid_idx <- !is.na(nearest_genes)
  if (sum(valid_idx) == 0) {
    next  # Skip if no valid nearest genes
  }
  
  # Subset features and nearest genes
  feature_gr_valid <- feature_gr[valid_idx]
  nearest_genes_valid <- nearest_genes[valid_idx]
  nearest_gene_info <- gene_gr_chr[nearest_genes_valid]
  
  # Calculate feature midpoints
  midpoint <- start(feature_gr_valid) + (width(feature_gr_valid) - 1) / 2
  
  # Calculate distances in base pairs
  distance_bp <- abs(midpoint - start(nearest_gene_info))
  
  # Determine direction (+ or -)
  direction <- ifelse(
    (midpoint - start(nearest_gene_info)) * ifelse(as.character(strand(nearest_gene_info)) == '+', 1, -1) >= 0,
    '+',
    '-'
  )
  
  # Convert distance to kilobases
  distance_kb <- floor(distance_bp / 1000)
  
  # Generate the feature names
  feature_name <- paste0(
    mcols(nearest_gene_info)$gene_name, "_f", direction, distance_kb
  )
  
  feature_names_df <- data.frame(
    seqnames = as.character(seqnames(feature_gr_valid)),
    start = start(feature_gr_valid),
    end = end(feature_gr_valid),
    feature_name = feature_name,
    stringsAsFactors = FALSE
  )
  # Insert the updated data into the temporary table
  dbWriteTable(con.obj, "temp_feature_names", feature_names_df, overwrite = TRUE, row.names = FALSE)
  
  # Update the feature table using seqnames, start, and end
  dbExecute(con.obj, "
    UPDATE feature
    SET feature_name = (
      SELECT temp_feature_names.feature_name
      FROM temp_feature_names
      WHERE feature.seqnames = temp_feature_names.seqnames
        AND feature.start = temp_feature_names.start
        AND feature.end = temp_feature_names.end
    )
    WHERE EXISTS (
      SELECT 1
      FROM temp_feature_names
      WHERE feature.seqnames = temp_feature_names.seqnames
        AND feature.start = temp_feature_names.start
        AND feature.end = temp_feature_names.end
    );
  ")
  
  # Clean Up: Remove the Temporary Table After Updating
  dbExecute(con.obj, "DROP TABLE IF EXISTS temp_feature_names;")

}



```

```{r Write TOBIAS data into SQlite, eval=TRUE}
dbWriteTable(con.obj, "tobias", tobias.tb.2, overwrite=TRUE)
dbListTables(con.obj)
rm(tobias.tb.2)
gc()
```

```{r Build indeces, eval=TRUE}
dbExecute(con.obj, 'CREATE INDEX seqname 
ON tobias (seqnames);')

dbExecute(con.obj, 'CREATE INDEX position 
ON tobias (seqnames, start, end);')

dbExecute(con.obj, 'CREATE INDEX TFBS_name 
ON tobias (TFBS_name);')

dbExecute(con.obj, 'CREATE INDEX features 
ON tobias (features);')
```

```{r}
tobias.tm <- dbGetQuery(con.obj, 'SELECT TFBS_name FROM tobias')

tobias.tm <- left_join(tobias.tm, dplyr::select(H12.metadata, TF.rep, masterlist_info.tf,ensg_id), by=c("TFBS_name"="TF.rep")) %>% distinct()
colnames(tobias.tm) <- c("TFBS_name","masterlist_info_tf","ensg_id")

dbWriteTable(con.obj, "gene_name_tmp", tobias.tm)
dbExecute(con.obj, 'CREATE INDEX TFBS_name_2 
ON gene_name_tmp (TFBS_name);')

dbExecute(con.obj, 'ALTER TABLE tobias ADD COLUMN TF_gene_name TEXT;')
dbExecute(con.obj, 'ALTER TABLE tobias ADD COLUMN ensg_id TEXT;')

dbExecute(con.obj, '
UPDATE tobias
SET TF_gene_name = (
    SELECT masterlist_info_tf
    FROM gene_name_tmp
    WHERE gene_name_tmp.TFBS_name = tobias.TFBS_name
),
ensg_id = (
    SELECT ensg_id
    FROM gene_name_tmp
    WHERE gene_name_tmp.TFBS_name = tobias.TFBS_name
);
')

dbExecute(con.obj, 'DROP TABLE gene_name_tmp;')

dbExecute(con.obj, 'CREATE INDEX TF_gene_name ON tobias (TF_gene_name);')
dbExecute(con.obj, 'CREATE INDEX ensg_id ON tobias (ensg_id);')
gc()
```

<!-- ```{r Reading conservation data} -->
<!-- cons.gr <- import.bw(con="../metadata/mm10.60way.phastCons.bw",as="GRanges") -->
<!-- ``` -->

<!-- ```{r} -->
<!-- TFBS.loc <- dbGetQuery(con, 'SELECT seqnames, start, end, TFBS_name FROM tobias WHERE seqnames IN ("chr1","chr2","chr3","chr4","chr5","chr6","chr7","chr8","chr9","chr10","chr11","chr12","chr13","chr14","chr15","chr16","chr17","chr18","chr19","chrX","chrY");') -->
<!-- ``` -->

<!-- ```{r} -->
<!-- uniq.seq.names <- unique(pull(TFBS.loc,seqnames)) -->

<!-- TFBS.loc.cons.list <- mclapply(uniq.seq.names, function(seq.name){ -->
<!--   message_parallel(paste("Processing",seq.name,sep=" ")) -->
<!--   gc() -->
<!--   TFBS.tmp <- makeGRangesFromDataFrame(filter(TFBS.loc, seqnames==seq.name)) -->
<!--   cons.subset <- cons.gr[seqnames(cons.gr)==seq.name] -->
<!--   overlaps <- findOverlaps(query = cons.subset, subject = TFBS.tmp, type = "within") -->
<!--   TFBS.cons <- mergeByOverlaps(query = cons.subset, subject = TFBS.tmp, type="within") -->
<!--   mcols(TFBS.cons$TFBS.tmp)$score <- TFBS.cons$score -->
<!--   TFBS.cons.means <- as_tibble(TFBS.cons$TFBS.tmp %>% plyranges::group_by(start,end) %>% summarize(mean.cons=mean(score))) -->
<!--   TFBS.cons.means$seqnames <-seq.name -->
<!--   return(TFBS.cons.means) -->
<!-- }, mc.cores = 1) -->


<!-- TFBS.loc.cons.tb <- do.call(rbind,TFBS.loc.cons.list) -->
<!-- colnames(TFBS.loc.cons.tb) <- c("start","end","mean_cons","seqnames") -->
<!-- tobias.cons.tmp <- left_join(TFBS.loc, TFBS.loc.cons.tb, by=c("seqnames","start","end")) -->

<!-- dbWriteTable(con, "TFBS_pos_cons_tmp", tobias.cons.tmp, overwrite=TRUE) -->
<!-- dbExecute(con, 'CREATE INDEX TFBS_loc_2 -->
<!-- ON TFBS_pos_cons_tmp (seqnames, start, end);') -->

<!-- dbExecute(con, 'ALTER TABLE tobias ADD COLUMN mean_cons REAL;') -->

<!-- dbExecute(con, ' -->
<!-- UPDATE tobias -->
<!-- SET mean_cons = ( -->
<!--     SELECT mean_cons -->
<!--     FROM TFBS_pos_cons_tmp -->
<!--     WHERE TFBS_pos_cons_tmp.seqnames = tobias.seqnames AND TFBS_pos_cons_tmp.start = tobias.start AND TFBS_pos_cons_tmp.end = tobias.end -->
<!-- )') -->


<!-- # Not all TFBS get conservation score, is this becuase of the conservation source data?? -->

<!-- dbExecute(con, 'DROP TABLE TFBS_pos_cons_tmp;') -->
<!-- ``` -->

```{r Conservation data}

# Function to load conservation data one chromosome at a time to manage memory use
import_bw_chunk <- function(chromosome) {
  gr <- GRanges(seqnames = chromosome, ranges = IRanges(start = 1, end = seqlengths(BSgenome.Mmusculus.UCSC.mm10)[chromosome]))
  import(con = "../metadata/mm10.60way.phastCons.bw", which = gr)
}

# Read TFBS locations from the database
TFBS.loc <- dbGetQuery(con.obj, 'SELECT seqnames, start, end, TFBS_name FROM tobias WHERE seqnames IN ("chr1","chr2","chr3","chr4","chr5","chr6","chr7","chr8","chr9","chr10","chr11","chr12","chr13","chr14","chr15","chr16","chr17","chr18","chr19","chrX","chrY");')

# Use data.table for efficient data manipulation
TFBS.loc <- as.data.table(TFBS.loc)
uniq.seq.names <- unique(TFBS.loc$seqnames)

# Function to process each chromosome
process_chromosome <- function(seq.name) {
  message_parallel(paste("Processing", seq.name))
  gc()

  # Load conservation data for the chromosome
  cons.gr <- import_bw_chunk(seq.name)
  if (length(cons.gr) == 0) return(NULL)

  # Subset TFBS for the chromosome
  TFBS.tmp <- TFBS.loc[seqnames == seq.name]
  if (nrow(TFBS.tmp) == 0) return(NULL)

  TFBS.gr <- makeGRangesFromDataFrame(TFBS.tmp)

  # Find overlaps
  overlaps <- findOverlaps(query = cons.gr, subject = TFBS.gr, type = "within")

  # Merge overlaps and compute mean conservation score
  if (length(overlaps) == 0) return(NULL)

  cons.subset <- cons.gr[queryHits(overlaps)]
  TFBS.subset <- TFBS.gr[subjectHits(overlaps)]
  TFBS.subset$score <- cons.subset$score

  TFBS.cons.means <- as_tibble(TFBS.subset %>% plyranges::group_by(start, end) %>% summarize(mean.cons = mean(score)))
  TFBS.cons.means$seqnames <- seq.name

  return(TFBS.cons.means)
}

# Process each chromosome in parallel
TFBS.loc.cons.list <- mclapply(uniq.seq.names, process_chromosome, mc.cores = 2)

# Filter out NULL results
TFBS.loc.cons.list <- Filter(Negate(is.null), TFBS.loc.cons.list)

# Combine results into one table
TFBS.loc.cons.tb <- rbindlist(TFBS.loc.cons.list, fill = TRUE)
colnames(TFBS.loc.cons.tb) <- c("start", "end", "mean_cons", "seqnames")

# Merge results back to original TFBS locations
tobias.cons.tmp <- merge(TFBS.loc, TFBS.loc.cons.tb, by = c("seqnames", "start", "end"), all.x = TRUE)

# Write results back to the database
dbWriteTable(con.obj, "TFBS_pos_cons_tmp", tobias.cons.tmp, overwrite = TRUE)
dbExecute(con.obj, 'CREATE INDEX TFBS_loc_2 ON TFBS_pos_cons_tmp (seqnames, start, end);')
dbExecute(con.obj, 'ALTER TABLE tobias ADD COLUMN mean_cons REAL;')

dbExecute(con.obj, '
UPDATE tobias
SET mean_cons = (
    SELECT mean_cons
    FROM TFBS_pos_cons_tmp
    WHERE TFBS_pos_cons_tmp.seqnames = tobias.seqnames AND TFBS_pos_cons_tmp.start = tobias.start AND TFBS_pos_cons_tmp.end = tobias.end
)')

dbExecute(con.obj, 'DROP TABLE TFBS_pos_cons_tmp;')

# Cleanup
gc()
```

```{r}
parse_meme_file <- function(file_path) {
  # Read the file content
  lines <- readLines(file_path)
  
  # Initialize variables
  motifs <- list()
  motif_name <- NULL
  matrix_start <- FALSE
  matrix_data <- NULL
  
  # Loop through each line to parse motifs and matrices
  for (line in lines) {
    if (startsWith(line, "MOTIF")) {
      # Save the previous matrix if we were reading one
      if (!is.null(motif_name) && !is.null(matrix_data)) {
        motifs[[motif_name]] <- matrix(matrix_data, ncol = ncol(matrix_data), byrow = TRUE)
      }
      # Start a new motif
      motif_name <- strsplit(line, " ")[[1]][2]
      matrix_data <- NULL
    } else if (startsWith(line, "letter-probability matrix")) {
      matrix_start <- TRUE
      next
    } else if (matrix_start) {
      if (line == "") {
        matrix_start <- FALSE
      } else {
        # Convert line to numeric and check if valid
        numeric_line <- as.numeric(unlist(strsplit(line, "\\s+")))
        if (all(!is.na(numeric_line))) {
          # Append the line to the matrix data
          matrix_data <- rbind(matrix_data, numeric_line)
        }
      }
    }
  }
  
  # Save the last matrix
  if (!is.null(motif_name) && !is.null(matrix_data)) {
    motifs[[motif_name]] <- matrix(matrix_data, ncol = ncol(matrix_data), byrow = TRUE)
  }
  
  return(motifs)
}

# Example usage
file_path <- "../mm10/Hocomoco.v12/H12CORE_meme_format.meme"
motifs.h12 <- parse_meme_file(file_path)

# Example usage
file_path.h11 <- "../mm10/Hocomoco.v11/HOCOMOCOv11_core_MOUSE_mono_meme_format.meme"
motifs.h11 <- parse_meme_file(file_path.h11)

motifs.h12[["INSM1_MOUSE.H11MO.0.C"]] <- motifs.h11[["INSM1_MOUSE.H11MO.0.C"]]

# Print the list of motifs and their matrices
tail(motifs.h12)

positional.mean.weights <- lapply(motifs.h12,rowMax)
names(positional.mean.weights) <- paste(names(positional.mean.weights),names(positional.mean.weights),sep="_")
```

```{r, eval=TRUE}
# Define a function to calculate the weighted mean for each group
calculate_weighted_mean <- function(data,positional.mean.weights) {
  TFBS_name <- unique(data$TFBS_name)
  if (length(TFBS_name) != 1) {
    stop("Each group should have exactly one TFB_name.")
  }
  weights <- positional.mean.weights[[TFBS_name]]
  if (is.null(weights)) {
    stop(paste("No weights found for TFB_name:", TFBS_name))
  }
  if (length(weights) != nrow(data)) {
    # Store information about the problematic group
    problematic_groups <<- append(problematic_groups, list(tibble(start = unique(data$start), end = unique(data$end), TFBS_name = TFBS_name, difference = length(weights)- nrow(data))))
    # Return NA
    mean.cons <- NA
  } else {
    # Calculate weighted mean
    mean.cons <- weighted.mean(data$score, weights)
  }
  tibble(start = unique(data$start), end = unique(data$end), TFBS_name = TFBS_name, mean.cons = mean.cons)
}


uniq.seq.names <- unique(pull(TFBS.loc,seqnames))

TFBS.loc.cons.list <- mclapply(uniq.seq.names, function(seq.name){
  message_parallel(paste("Processing",seq.name,sep=" "))
  gc()
  TFBS.tmp <- makeGRangesFromDataFrame(dplyr::filter(TFBS.loc, seqnames==seq.name), keep.extra.columns = T)
  cons.subset <- import_bw_chunk(seq.name)
  
  # Split TFBS.tmp into single-base intervals
  TFBS.tmp.split <- unlist(tile(TFBS.tmp, width=1))

  # Replicate metadata to each single-base interval
  metadata <- as.data.frame(mcols(TFBS.tmp))
  metadata_rep <- metadata[rep(1:nrow(metadata), lengths(tile(TFBS.tmp, width=1))), ]
  mcols(TFBS.tmp.split) <- metadata_rep
  
  # Find overlaps between single-base intervals and cons.subset
  overlaps <- findOverlaps(query = cons.subset, subject = TFBS.tmp.split)

  # Create a data frame from TFBS.tmp.split
  TFBS.df <- as.data.frame(TFBS.tmp.split)
  colnames(TFBS.df)[colnames(TFBS.df) == "X"] <- "TFBS_name"
  
  # Initialize the score column with NA
  TFBS.df$score <- NA

  # Get the indices of the overlapping regions
  query_hits <- queryHits(overlaps)
  subject_hits <- subjectHits(overlaps)

  # Copy the score from cons.subset to TFBS.df
  TFBS.df$score[subject_hits] <- mcols(cons.subset)$score[query_hits]

  # Create a grouping variable to identify consecutive ranges
  TFBS.df <- TFBS.df %>%
  arrange(TFBS_name, start, end) %>%
  mutate(group = cumsum(c(1, diff(start) != 1 | diff(as.numeric(factor(TFBS_name))) != 0)))
  
# TFBS.df <- TFBS.df %>%
#   arrange(TFBS_name, start) %>%
#   mutate(is_consecutive = (start == dplyr::lag(end, default = dplyr::first(start))) & (TFBS_name == dplyr::lag(TFBS_name, default = dplyr::first(TFBS_name))), group = cumsum(!is_consecutive)) %>%
#   dplyr::select(-is_consecutive)

  # Update each row within the group to have the smallest start and largest end
  TFBS.df <- TFBS.df %>%
  group_by(group, TFBS_name) %>%
  mutate(start = min(start), end = max(end)) %>%
  ungroup() %>%
  dplyr::select(-group)  # Remove the temporary group column

  TFBS.cons.means <- TFBS.df %>% group_by(start,end,TFBS_name) %>% group_split() %>%
  map_dfr(~ calculate_weighted_mean(.x,positional.mean.weights=positional.mean.weights))
  TFBS.cons.means$seqnames <-seq.name
  return(TFBS.cons.means)
}, mc.cores = 2)

TFBS.loc.cons.tb <- do.call(rbind,TFBS.loc.cons.list)
colnames(TFBS.loc.cons.tb) <- c("start","end","TFBS_name","w.mean_cons","seqnames")
tobias.cons.tmp <- left_join(TFBS.loc, TFBS.loc.cons.tb, by=c("seqnames","start","end","TFBS_name"))

tobias.cons.tmp <- rename(tobias.cons.tmp, "w.mean_cons"="w_mean_cons")

dbWriteTable(con.obj, "TFBS_pos_cons_tmp", tobias.cons.tmp, overwrite=TRUE)
dbExecute(con.obj, 'CREATE INDEX TFBS_loc_2
ON TFBS_pos_cons_tmp (seqnames, start, end);')

dbExecute(con.obj, 'ALTER TABLE tobias ADD COLUMN w_mean_cons REAL;')

dbExecute(con.obj, '
UPDATE tobias
SET w_mean_cons = (
    SELECT w_mean_cons
    FROM TFBS_pos_cons_tmp
    WHERE TFBS_pos_cons_tmp.seqnames = tobias.seqnames AND TFBS_pos_cons_tmp.start = tobias.start AND TFBS_pos_cons_tmp.end = tobias.end
)')

dbExecute(con.obj, 'DROP TABLE TFBS_pos_cons_tmp;')
```

# Calculate expression and accessibility information into the database

```{r Calculate and upload average gene expression data per cell group into separate table}
ensg_ids <- dbGetQuery(con.obj, 'SELECT DISTINCT ensg_id FROM tobias;')[,1]

TF.expression.data.avg2 <- AverageExpression(dataset, assays = "RNA", features = ensg_ids, group.by = "rv2.lineage_re", layer = "data")[[1]]

dbWriteTable(con.obj, "exp", as.data.frame(TF.expression.data.avg2) %>% rownames_to_column("ensg_id") %>% as_tibble(), overwrite=TRUE)

dbExecute(con.obj, 'CREATE INDEX ensg_ids_2 ON exp (ensg_id);')
```

```{r Calculate and upload z-score normalized gene expression averages per TF gene per cell group into separate table, eval=FALSE}
ensg_ids <- dbGetQuery(con.obj, 'SELECT DISTINCT ensg_id FROM tobias;')[,1]

DefaultAssay(dataset) <- "RNA"
TF.expression.data <- FetchData(object=dataset, assays = "RNA", vars = c(ensg_ids,"rv2.lineage_re"))
TF.expression.data.mat <- as.matrix(expm1(as_tibble(TF.expression.data) %>% select(!starts_with("rv"))))
TF.expression.data.mat <- as_tibble(t(scale(t(TF.expression.data.mat))))
TF.expression.data.mat$rv2.lineage_re <- TF.expression.data$rv2.lineage_re
TF.expression.data.mat <- pivot_longer(TF.expression.data.mat, cols = !starts_with("rv"))

TF.expr.scaled <- TF.expression.data.mat %>% group_by(rv2.lineage_re, name) %>% summarise(avg.exp=mean(value,na.rm=T)) %>% pivot_wider(values_from = avg.exp, names_from = rv2.lineage_re)

names(TF.expr.scaled)[1] <- "ensg_id"

dbWriteTable(con, "exp_scaled", TF.expr.scaled, overwrite=TRUE)

dbExecute(con, 'CREATE INDEX ensg_ids_3 ON exp_scaled (ensg_id);')
```

```{r Calculate and upload feature accessibility data per feature per cell group into separate table }
features <- dbGetQuery(con.obj, 'SELECT DISTINCT features FROM tobias;')[,1]

acc.avg.data <- AverageExpression(dataset, assays = "peaks", features = features, group.by = "rv2.lineage_re")[[1]]

dbWriteTable(con.obj, "acc", as.data.frame(acc.avg.data) %>% rownames_to_column("features") %>% as_tibble(), overwrite=TRUE)

dbExecute(con.obj, 'CREATE INDEX features_2 ON acc (features);')
```

```{r Additional corrections to TF_gene_name field}
dbExecute(con.obj, "UPDATE tobias
SET TF_gene_name = 'NGN1'
WHERE TF_gene_name LIKE '1,0%NGN';")

dbExecute(con.obj, "UPDATE tobias
SET TF_gene_name = 'NGN2'
WHERE TF_gene_name LIKE '2,0%NGN';")

dbExecute(con.obj, "UPDATE tobias
SET TF_gene_name = 'MAD4'
WHERE TF_gene_name LIKE '4,0%MAD';")
```

```{r links_s}
# Load data and prepare objects
E12_rV2 <- qread(file = "../scATAC_data/nmm_rV2_subset_relabeled_031023_links.qs", nthreads = cores)
DefaultAssay(E12_rV2) <- "peaks"
Links(E12_rV2) <- GenomicRanges::GRanges()

mm10.v79.genome.GR <- toGRanges(
  EnsDb.Mmusculus.v79,
  feature = c("gene", "transcript", "exon", "disjointExons")
)
mm10.v79.genome.GR$gene_id <- names(mm10.v79.genome.GR)
DefaultAssay(E12_rV2) <- "RNA"

gene_ids <- unique(intersect(names(mm10.v79.genome.GR), rownames(E12_rV2)))

# Read TAD map
TAD.map <- read_table("../metadata/cb.csail.mit.edu_cb_tadmap_TADMap_scaffold_mm.bed.txt", col_names = c("seqnames", "start", "end")) %>% GRanges()

dbWriteTable(con.obj, "TAD", as_tibble(TAD.map), overwrite=TRUE)

# Function to process each gene ID
process_gene_id <- function(i) {
  idx <- gene_ids[i]
  message_parallel(paste(i,"/",length(gene_ids),sep=""))
  
  # Find the TAD for the gene in question
  gene.range <- mm10.v79.genome.GR[which(names(mm10.v79.genome.GR) == idx)]
  TAD.overlap <- plyranges::filter_by_overlaps(TAD.map, gene.range)
  
  tryCatch({
    Link.Seurat <- LinkPeaks(
      object = E12_rV2, peak.assay = "peaks", expression.assay = "RNA",
      genes.use = idx, gene.id = TRUE, distance = width(TAD.overlap),
      gene.coords = mm10.v79.genome.GR, peak.slot = "counts",
      expression.slot = "data", method = "spearman"
    )
    
  links.tb <- as_tibble(Link.Seurat@assays$peaks@links) %>% rename("peak"="feature") %>% rename("gene"="ensg_id")
    
    success <- FALSE
    con.obj <- DBI::dbConnect(RSQLite::SQLite(), dbname = "~/Workspace/TOBIAS.dr.h12_191124.sqlite")
    while (!success) {
      tryCatch({
        dbWriteTable(con.obj, "links_s", links.tb, overwrite = FALSE, append = TRUE)
        success <- TRUE
      }, error = function(e) {
        Sys.sleep(0.25)
      })
    }
  }, error = function(e) {
    cat("An error occurred:", e$message, "\n")
  }, warning = function(w) {
    cat("A warning occurred:", w$message, "\n")
  })
  DBI::dbDisconnect(con.obj)
}

# Process gene IDs in parallel
mclapply(1:length(gene_ids), process_gene_id, mc.cores = 6)

# Close the database connection
#DBI::dbDisconnect(con.obj)

dbExecute(con.obj, 'CREATE INDEX ensg_id5_s ON links_s (ensg_id);')
dbExecute(con.obj, 'CREATE INDEX feature4_s ON links_s (feature);')
dbExecute(con.obj, 'CREATE INDEX zscore1_s ON links_s (zscore);')
dbExecute(con.obj, 'CREATE INDEX links_pvalue_s ON links_s (pvalue);')
```

```{r links}
# Load data and prepare objects
E12_rV2 <- qread(file = "../scATAC_data/nmm_rV2_subset_relabeled_031023_links.qs", nthreads = cores)
DefaultAssay(E12_rV2) <- "peaks"
Links(E12_rV2) <- GenomicRanges::GRanges()

mm10.v79.genome.GR <- toGRanges(
  EnsDb.Mmusculus.v79,
  feature = c("gene", "transcript", "exon", "disjointExons")
)
mm10.v79.genome.GR$gene_id <- names(mm10.v79.genome.GR)
DefaultAssay(E12_rV2) <- "RNA"

gene_ids <- unique(intersect(names(mm10.v79.genome.GR), rownames(E12_rV2)))

# Read TAD map
TAD.map <- read_table("../metadata/cb.csail.mit.edu_cb_tadmap_TADMap_scaffold_mm.bed.txt", col_names = c("seqnames", "start", "end")) %>% GRanges()

con.obj <- DBI::dbConnect(RSQLite::SQLite(), dbname = "~/Workspace/TOBIAS.dr.h12_191124.sqlite")
dbWriteTable(con.obj, "TAD", as_tibble(TAD.map), overwrite=TRUE)
DBI::dbDisconnect(con.obj)

# Function to process each gene ID
process_gene_id <- function(i) {
  idx <- gene_ids[i]
  message_parallel(paste(i,"/",length(gene_ids),sep=""))
  
  # Find the TAD for the gene in question
  gene.range <- mm10.v79.genome.GR[which(names(mm10.v79.genome.GR) == idx)]
  TAD.overlap <- plyranges::filter_by_overlaps(TAD.map, gene.range)
  
  tryCatch({
    Link.Seurat <- LinkPeaks(
      object = E12_rV2, peak.assay = "peaks", expression.assay = "RNA",
      genes.use = idx, gene.id = TRUE, distance = width(TAD.overlap),
      gene.coords = mm10.v79.genome.GR, peak.slot = "counts",
      expression.slot = "data", method = "pearson"
    )
    
  links.tb <- as_tibble(Link.Seurat@assays$peaks@links) %>% dplyr::rename("feature"="peak") %>% dplyr::rename("ensg_id"="gene")
    
    success <- FALSE
    con.obj <- DBI::dbConnect(RSQLite::SQLite(), dbname = "~/Workspace/TOBIAS.dr.h12_191124.sqlite")
    while (!success) {
      tryCatch({
        dbWriteTable(con.obj, "links", links.tb, overwrite = FALSE, append = TRUE)
        success <- TRUE
      }, error = function(e) {
        Sys.sleep(0.25)
      })
    }
  }, error = function(e) {
    cat("An error occurred:", e$message, "\n")
  }, warning = function(w) {
    cat("A warning occurred:", w$message, "\n")
  })
  DBI::dbDisconnect(con.obj)
}

# Process gene IDs in parallel
mclapply(1:length(gene_ids), process_gene_id, mc.cores = 3)

# Close the database connection
#DBI::dbDisconnect(con.obj)

dbExecute(con.obj, 'CREATE INDEX ensg_id5_s ON links (ensg_id);')
dbExecute(con.obj, 'CREATE INDEX feature4_s ON links (feature);')
dbExecute(con.obj, 'CREATE INDEX zscore1_s ON links (zscore);')
dbExecute(con.obj, 'CREATE INDEX links_pvalue_s ON links (pvalue);')
```


```{r Calculating LinkPeaks within TADs, eval=FALSE}
E12_rV2 <- qread(file = "../scATAC_data/nmm_rV2_subset_relabeled_031023_links.qs", nthreads = cores)

DefaultAssay(E12_rV2) <- "peaks"

Links(E12_rV2) <- GenomicRanges::GRanges()

mm10.v79.genome.GR <- toGRanges(
  EnsDb.Mmusculus.v79,
  feature = c("gene", "transcript", "exon", "disjointExons")
)

mm10.v79.genome.GR$gene_id <- names(mm10.v79.genome.GR)

DefaultAssay(E12_rV2) <- "RNA"

gene_ids <- unique(intersect(names(mm10.v79.genome.GR),rownames(E12_rV2)))

#the information about TAD areas - https://cb.csail.mit.edu/cb/tadmap/
TAD.map <- read_table("../metadata/cb.csail.mit.edu_cb_tadmap_TADMap_scaffold_mm.bed.txt", col_names = c("seqnames", "start", "end")) %>% GRanges()

#Function
links.within.TADs <- mclapply(gene_ids, function(idx){
  message_parallel(idx)
  con.obj <- DBI::dbConnect(RSQLite::SQLite(), dbname = "~/Workspace/TOBIAS.dr.h12_140524.sqlite")
  
  #first we find the TAD - topologically associated domain - for gene in a question
  gene.range <- mm10.v79.genome.GR[which(names(mm10.v79.genome.GR) == idx)]

  TAD.overlap <-plyranges::filter_by_overlaps(TAD.map,gene.range)
  tryCatch({
    Link.Seurat <- LinkPeaks(object = E12_rV2, peak.assay = "peaks", expression.assay = "RNA", genes.use = idx, gene.id = T, distance = width(TAD.overlap), gene.coords = mm10.v79.genome.GR,  peak.slot = "counts", expression.slot = "data", method = "pearson")
  
    links.tb <- as_tibble(Link.Seurat@assays$peaks@links) %>% rename("feature"="peak") %>% rename("ensg_id"="gene")
    success <- FALSE
    while(!success & base::exists("links.tb")) {
      tryCatch({
       dbWriteTable(con.obj, "links", links.tb, overwrite=FALSE, append=TRUE)
        success<-TRUE
      }, error = function(e) {
        Sys.sleep(0.25)
      })
    }
    },
  error = function(e) {
    cat("An error occurred:", e$message, "\n")
    },
  warning = function(w) {
    cat("A warning occurred:", w$message, "\n")
  })
  # Handle warning if necessary)
  DBI::dbDisconnect(con.obj)
  #return(links)
}, mc.cores = cores)

dbExecute(con.obj, 'CREATE INDEX ensg_id5 ON links (ensg_id);')
dbExecute(con.obj, 'CREATE INDEX feature4 ON links (feature);')
dbExecute(con.obj, 'CREATE INDEX zscore1 ON links (zscore);')
dbExecute(con.obj, 'CREATE INDEX links_pvalue ON links (pvalue);')
```

```{r, eval=FALSE}
links.within.TADs <- qread("../analysis/links.within.TADs.qs")


check_identity <- function(tibble_in_list) {
  any(pmap_lgl(B, ~ identical(tibble_in_list, tibble(...))))
}

DefaultAssay(E12_rV2) <- "peaks"
B <- as_tibble(Links(E12_rV2))


identical_elements <- map_lgl(links.within.TADs, check_identity)


links.within.TADs.tb <- do.call(rbind,links.within.TADs) %>% dplyr::filter(!is.na(seqnames))

con <- DBI::dbConnect(RSQLite::SQLite(), dbname = "~/Workspace/TOBIAS.dr.h12_110424.sqlite")
success <- dbWriteTable(con, "links", links.within.TADs.tb, overwrite=TRUE)

dbExecute(con, 'CREATE INDEX ensg_id5 ON links (ensg_id);')
dbExecute(con, 'CREATE INDEX feature4 ON links (feature);')
dbExecute(con, 'CREATE INDEX zscore1 ON links (zscore);')
dbExecute(con, 'CREATE INDEX links_pvalue ON links (pvalue);')

DBI::dbDisconnect(con)
```

```{r C&T data import 1}
consensus.beds.path <- list.files(path="/Volumes/MyBookDuo/Data/Cut_Tag/out_030524/03_peak_calling/05_consensus_peaks/", pattern = "*.awk.bed", full.names = T)

consensus.beds <- lapply(consensus.beds.path, function(path){
  tmp.1 <- read_delim(file = path, col_names = c("chr","start","end","start_merged","end_merged","total_signals","max_signals","max_signal_regions","sample_names","consensus_replicate_count"))
  if (nrow(tmp.1)>0){
  tmp.1$target_gene_name <- str_extract(string=tmp.1$sample_names, pattern = "(?<=_)[^_]+(?=_)")
  return(tmp.1)
  } else {
    return(NA)
  }
  })

consensus.beds.tb <- do.call(rbind,consensus.beds)
consensus.beds.tb <- consensus.beds.tb %>% mutate(row_id = row_number()) 

# Normalize the data (in SQL sense)
normalized_data <- consensus.beds.tb %>%
  # Create an index to keep track of the original row positions
  # Expand the rows based on the comma-separated values
  separate_rows(total_signals, max_signals, max_signal_regions,sample_names, sep = ",") %>%
  # Group by the original row index to ensure correct order
  group_by(row_id) %>%
  # Create a new ID to ensure uniqueness
  mutate(normalized_id = row_number()) %>%
  ungroup()

normalized_data<-normalized_data[!is.na(normalized_data$chr),]
normalized_data$start <- normalized_data$start+1

ct.gr <- makeGRangesFromDataFrame(normalized_data,na.rm=T, keep.extra.columns = T)
feat.gr <- all.features

# Assuming ct.gr and feat.gr are already defined GRanges objects
# Find overlaps
overlaps <- findOverlaps(ct.gr, feat.gr)

# Assuming 'A' is your original tibble that corresponds to ct.gr
# Let's add an identifier to 'A' for the linkage
normalized_data <- normalized_data %>% mutate(row_id = row_number())

# Extract overlapping information with a new 'feature' column that combines 'chr', 'start', 'end'
overlap_info <- tibble(
  row_id = queryHits(overlaps),
  feature = paste(seqnames(feat.gr)[subjectHits(overlaps)], 
                  start(feat.gr)[subjectHits(overlaps)], 
                  end(feat.gr)[subjectHits(overlaps)], 
                  sep = "-")
)

normalized_data_expanded <- normalized_data %>%
  right_join(overlap_info, by = "row_id")

normalized_data_expanded <- normalized_data_expanded %>% mutate(start=as.integer(start), end=as.integer(end), total_signals=as.numeric(total_signals), max_signals=as.numeric(max_signals), consensus_replicate_count=as.integer(consensus_replicate_count))

dbWriteTable(con.obj, "CT_data", normalized_data_expanded, overwrite=TRUE)
dbExecute(con.obj, 'CREATE INDEX CT_data_feature ON CT_data (feature);')
dbExecute(con.obj, 'CREATE INDEX CT_data_max_signals ON CT_data (max_signals);')
dbExecute(con.obj, 'CREATE INDEX CT_data_target_gene_name ON CT_data (target_gene_name);')
dbExecute(con.obj, 'CREATE INDEX CT_feature_target_gene_name ON CT_data (feature, target_gene_name);')
```

```{r C&T data import 2}
consensus.beds.path <- list.files(path="/Volumes/MyBookDuo/Data/Cut_Tag/out_030924/03_peak_calling/05_consensus_peaks/", pattern = "*.awk.bed", full.names = T)

consensus.beds <- lapply(consensus.beds.path, function(path){
  tmp.1 <- read_delim(file = path, col_names = c("chr","start","end","start_merged","end_merged","total_signals","max_signals","max_signal_regions","sample_names","consensus_replicate_count"))
  if (nrow(tmp.1)>0){
  tmp.1$target_gene_name <- str_extract(string=tmp.1$sample_names, pattern = "(?<=_)[^_]+(?=_)")
  return(tmp.1)
  } else {
    return(NA)
  }
  })

consensus.beds.tb <- do.call(rbind,consensus.beds)
consensus.beds.tb <- consensus.beds.tb %>% mutate(row_id = row_number()) 

# Normalize the data (in SQL sense)
normalized_data <- consensus.beds.tb %>%
  # Create an index to keep track of the original row positions
  # Expand the rows based on the comma-separated values
  separate_rows(total_signals, max_signals, max_signal_regions,sample_names, sep = ",") %>%
  # Group by the original row index to ensure correct order
  group_by(row_id) %>%
  # Create a new ID to ensure uniqueness
  mutate(normalized_id = row_number()) %>%
  ungroup()

normalized_data<-normalized_data[!is.na(normalized_data$chr),]
normalized_data$start <- normalized_data$start+1

ct.gr <- makeGRangesFromDataFrame(normalized_data,na.rm=T, keep.extra.columns = T)
feat.gr <- all.features

# Assuming ct.gr and feat.gr are already defined GRanges objects
# Find overlaps
overlaps <- findOverlaps(ct.gr, feat.gr)

# Assuming 'A' is your original tibble that corresponds to ct.gr
# Let's add an identifier to 'A' for the linkage
normalized_data <- normalized_data %>% mutate(row_id = row_number())

# Extract overlapping information with a new 'feature' column that combines 'chr', 'start', 'end'
overlap_info <- tibble(
  row_id = queryHits(overlaps),
  feature = paste(seqnames(feat.gr)[subjectHits(overlaps)], 
                  start(feat.gr)[subjectHits(overlaps)], 
                  end(feat.gr)[subjectHits(overlaps)], 
                  sep = "-")
)

normalized_data_expanded <- normalized_data %>%
  right_join(overlap_info, by = "row_id")

normalized_data_expanded <- normalized_data_expanded %>% mutate(start=as.integer(start), end=as.integer(end), total_signals=as.numeric(total_signals), max_signals=as.numeric(max_signals), consensus_replicate_count=as.integer(consensus_replicate_count))

dbWriteTable(con.obj, "CT_data", normalized_data_expanded, append=TRUE)
```

```{r Ensure all indeces are in place}
dbExecute(con.obj, "CREATE INDEX IF NOT EXISTS idx_tobias_TF_gene_name ON Tobias(TF_gene_name);")
dbExecute(con.obj, "CREATE INDEX IF NOT EXISTS idx_tobias_features ON Tobias(features);")
dbExecute(con.obj, "CREATE INDEX IF NOT EXISTS idx_tobias_TFBS_name ON Tobias(TFBS_name);")
dbExecute(con.obj, "CREATE INDEX IF NOT EXISTS idx_links_s_feature ON links_s(feature);")
dbExecute(con.obj, "CREATE INDEX IF NOT EXISTS idx_links_s_zscore ON links_s(zscore);")
dbExecute(con.obj, "CREATE INDEX IF NOT EXISTS idx_links_s_pvalue ON links_s(pvalue);")
dbExecute(con.obj, "CREATE INDEX IF NOT EXISTS idx_CT_data_feature ON CT_data(feature);")
dbExecute(con.obj, "CREATE INDEX IF NOT EXISTS idx_CT_data_target_gene_name ON CT_data(target_gene_name);")
dbExecute(con.obj, "CREATE INDEX IF NOT EXISTS idx_gene_metadata_ensg_id ON gene_metadata(ensg_id);")

queries <- c(
  # For tobias table
  "CREATE INDEX IF NOT EXISTS idx_tobias_ensg_id ON tobias(ensg_id);",
  "CREATE INDEX IF NOT EXISTS idx_tobias_features ON tobias(features);",
  "CREATE INDEX IF NOT EXISTS idx_tobias_w_mean_cons ON tobias(w_mean_cons);",
  "CREATE INDEX IF NOT EXISTS idx_tobias_PRO1_2_bound ON tobias(PRO1_2_bound);",
  "CREATE INDEX IF NOT EXISTS idx_tobias_CO1_2_bound ON tobias(CO1_2_bound);",
  "CREATE INDEX IF NOT EXISTS idx_tobias_GA1_2_bound ON tobias(GA1_2_bound);",
  "CREATE INDEX IF NOT EXISTS idx_tobias_GA3_4_bound ON tobias(GA3_4_bound);",
  "CREATE INDEX IF NOT EXISTS idx_tobias_GA5_6_bound ON tobias(GA5_6_bound);",
  "CREATE INDEX IF NOT EXISTS idx_tobias_GL1_2_bound ON tobias(GL1_2_bound);",
  "CREATE INDEX IF NOT EXISTS idx_tobias_GL3_4_bound ON tobias(GL3_4_bound);",
  "CREATE INDEX IF NOT EXISTS idx_tobias_GL5_bound ON tobias(GL5_bound);",

  # For exp table
  "CREATE INDEX IF NOT EXISTS idx_exp_ensg_id ON exp(ensg_id);",
  "CREATE INDEX IF NOT EXISTS idx_exp_PRO1_2 ON exp(PRO1_2);",
  "CREATE INDEX IF NOT EXISTS idx_exp_CO1_2 ON exp(CO1_2);",
  "CREATE INDEX IF NOT EXISTS idx_exp_GA1_2 ON exp(GA1_2);",
  "CREATE INDEX IF NOT EXISTS idx_exp_GA3_4 ON exp(GA3_4);",
  "CREATE INDEX IF NOT EXISTS idx_exp_GA5_6 ON exp(GA5_6);",
  "CREATE INDEX IF NOT EXISTS idx_exp_GL1_2 ON exp(GL1_2);",
  "CREATE INDEX IF NOT EXISTS idx_exp_GL3_4 ON exp(GL3_4);",
  "CREATE INDEX IF NOT EXISTS idx_exp_GL5 ON exp(GL5);",

  # For acc table
  "CREATE INDEX IF NOT EXISTS idx_acc_features ON acc(features);",
  "CREATE INDEX IF NOT EXISTS idx_acc_PRO1_2 ON acc(PRO1_2);",
  "CREATE INDEX IF NOT EXISTS idx_acc_CO1_2 ON acc(CO1_2);",
  "CREATE INDEX IF NOT EXISTS idx_acc_GA1_2 ON acc(GA1_2);",
  "CREATE INDEX IF NOT EXISTS idx_acc_GA3_4 ON acc(GA3_4);",
  "CREATE INDEX IF NOT EXISTS idx_acc_GA5_6 ON acc(GA5_6);",
  "CREATE INDEX IF NOT EXISTS idx_acc_GL1_2 ON acc(GL1_2);",
  "CREATE INDEX IF NOT EXISTS idx_acc_GL3_4 ON acc(GL3_4);",
  "CREATE INDEX IF NOT EXISTS idx_acc_GL5 ON acc(GL5);",

  # For links_s table
  "CREATE INDEX IF NOT EXISTS idx_links_feature ON links_s(feature);",
  "CREATE INDEX IF NOT EXISTS idx_links_ensg_id ON links_s(ensg_id);",
  "CREATE INDEX IF NOT EXISTS idx_links_zscore ON links_s(zscore);",
  
  # For links table
  "CREATE INDEX IF NOT EXISTS idx_links_p_feature ON links(feature);",
  "CREATE INDEX IF NOT EXISTS idx_links_p_ensg_id ON links(ensg_id);",
  "CREATE INDEX IF NOT EXISTS idx_links_p_zscore ON links(zscore);",

  # For gene_metadata table
  "CREATE INDEX IF NOT EXISTS idx_gene_metadata_ensg_id ON gene_metadata(ensg_id);",
  "CREATE INDEX IF NOT EXISTS idx_gene_metadata_gene_name ON gene_metadata(gene_name);"
)

# Execute all queries
for (query in queries) {
  dbExecute(con.obj, query)
}
```


# Misc


```{r}
DefaultAssay(dataset) <- "peaks"
acc.data.matrix <- FetchData(dataset, vars = rownames(dataset))
zero.test <- apply(acc.data.matrix,2,function(col){!all(col==0)})
acc.data.matrix<- acc.data.matrix[,zero.test]
DefaultAssay(dataset) <- "RNA"

TF_ensg_ids <- unique(dbGetQuery(con, 'SELECT ensg_id FROM tobias;')[,1])
DBI::dbDisconnect(con)

mclapply(TF_ensg_ids, function(ensg_id){
  tryCatch({
    exp.data.matrix <- FetchData(dataset, vars = ensg_id)
    if (!all(exp.data.matrix[,1]==0)){
    #message_parallel(paste("Calculating gene ",ensg_id))
    test.res <- na.omit(cor(exp.data.matrix,acc.data.matrix, method = "spearman", use="pairwise.complete.obs"))
    data.to.db <- tibble(ensg_id=rownames(test.res),feature=colnames(test.res),cor=test.res[1,])
    
    success <- FALSE
    con.obj <- DBI::dbConnect(RSQLite::SQLite(), dbname = "~/Workspace/TOBIAS.dr.h12_130324.sqlite")
    while(!success) {
      tryCatch({
        success <- dbWriteTable(con.obj, "gene2feat_cor", data.to.db, overwrite=FALSE, append=TRUE)
        DBI::dbDisconnect(con.obj)
      }, error = function(e) {
        Sys.sleep(0.25)
      }, warning = function(e) {
        e
      })
    }
    }
    
    
  }, error=function(cond){
    cond
  },warning=function(cond){
    cond
  })
  
},mc.cores=3)
dbExecute(con, 'CREATE INDEX gene2feat_cor_ensg_id ON gene2feat_cor (ensg_id);')
dbExecute(con, 'CREATE INDEX gene2feat_cor_cor ON gene2feat_cor (cor);')
dbExecute(con, 'CREATE INDEX gene2feat_cor_feature ON gene2feat_cor (feature);')
```


```{r Finding consequent motif areas}
tobias.table <- tbl(con, "tobias")
exp.table <- tbl(con, "exp")
acc.table <- tbl(con, "acc")
table.tmp.1 <- tobias.table %>% left_join(exp.table) %>% left_join(acc.table, by=c("features"="features")) %>% dplyr::filter(mean_cons>0.5)
table.tmp.2 <- table.tmp.1 %>% collect()

acc.thr <- quantile(acc.table %>% dplyr::select(!starts_with("features")) %>% pull(),.25)
mean_cons_thr<-0.5

table.tmp.2 <- table.tmp.2 %>% dplyr::filter((abs(PRO1_2.x)>1.2 | abs(CO1_2.x)>1.2 | abs(GA1_2.x)>1.2 | abs(GL1_2.x)>1.2) & (abs(PRO1_2.y)>acc.thr | abs(CO1_2.y)>acc.thr | abs(GA1_2.y)>acc.thr | abs(GL1_2.y)>acc.thr) & (PRO1_2_bound==1 | CO1_2_bound==1 | GA1_2_bound==1 | GL1_2_bound==1) & mean_cons>mean_cons_thr) %>% arrange(start)

grB <- makeGRangesFromDataFrame(dplyr::select(table.tmp.2, seqnames, start, end, TFBS_name), keep.extra.columns = T)

reduced_grB_with_map <- reduce(grB, min.gapwidth=0L,with.revmap = TRUE)


# Step 2: Concatenate metadata based on the revmap information
concatenated_metadata <- mclapply(reduced_grB_with_map$revmap, function(indices) {
  if (length(indices) > 0) {
    meta_values <- mcols(grB)[indices, ]
    paste(unique(na.omit(meta_values)), collapse = "; ")
  } else {
    ""
  }
}, mc.cores = 10)

mcols(reduced_grB_with_map)$concatenated_metadata <- concatenated_metadata

plyranges::filter_by_overlaps(reduced_grB_with_map,StringToGRanges("chr4-114432894-115134633"))
mcols(plyranges::filter_by_overlaps(reduced_grB_with_map,StringToGRanges("chr4-114432894-115134633")))$concatenated_metadata

saveRDS(reduced_grB_with_map,"../analysis/TFBS_reduced_positions_120324.Rds")
```

```{r Calculating TFBS binding probability background}
genes_TF_count <- dbGetQuery(con, 'SELECT li.ensg_id,
       tb.TF_gene_name,
       COUNT(tb.TF_gene_name) AS count
FROM links AS li
JOIN tobias AS tb ON tb.features = li.feature
WHERE li.zscore > 2 AND tb.mean_cons>0.5
GROUP BY li.ensg_id, tb.TF_gene_name;')
```

```{r}
genes_TF_count.wide <- pivot_wider(genes_TF_count,names_from = ensg_id, values_from = count)
#genes_TF_count.wide[is.na(genes_TF_count.wide)] <-0
genes_TF_count.wide.mat <- as.matrix(genes_TF_count.wide[,-1])
rownames(genes_TF_count.wide.mat) <- genes_TF_count.wide$TF_gene_name

# Parameters for the sigmoid function
a <- .15
b <- 0

# Calculate binding_probs using a sigmoid function
binding_probs <- 1 / (1 + exp(-(a * genes_TF_count.wide.mat + b)))

mean_binding_probs <- apply(binding_probs, 1, function(x) mean(x,na.rm=T))

lambda <- sum(mean_binding_probs)

C <- 3
prob_exact <- dpois(C, lambda)
```

