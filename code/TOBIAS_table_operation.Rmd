---
title: "R Notebook of TOBIAS table operations"
output: html_document
---

```{r Packages, message=FALSE}
library(rtracklayer)
library(qs)
library(Seurat)
library(Signac)
library(tidyverse)
library(GenomicRanges)
library(parallel)
library(dbplyr)
library(DBI)
library(hash)
library(EnsDb.Mmusculus.v79)
library(BSgenome.Mmusculus.UCSC.mm10)
library(ChIPpeakAnno)
cores <-10
source("../../AuxCode/AuxFunctions.R")
source("../../AuxCode/TOBIAS_tools.R")
library(rtracklayer)
library(plyranges)
library(data.table)
```

```{r Additional functions}
message_parallel <- function(...){
  system(sprintf('echo "\n%s\n"', paste0(..., collapse="")))
}
```

```{r Reading Seurat dataobject}
dataset <- qread("../scATAC_data/nmm_rV2_subset_relabeled_031023_links.qs", nthreads = cores)
DefaultAssay(dataset) <- "RNA"

dataset$rv2.lineage_re <- case_when(
  dataset$rv2.lineage %in% "PRO1" ~ "PRO1_2",
  dataset$rv2.lineage %in% "PRO2" ~ "PRO1_2",
  dataset$rv2.lineage %in% "GA1" ~ "GA1_2",
  dataset$rv2.lineage %in% "GA2" ~ "GA1_2",
  dataset$rv2.lineage %in% "GA3" ~ "GA3_4",
  dataset$rv2.lineage %in% "GA4" ~ "GA3_4",
  dataset$rv2.lineage %in% "GA5" ~ "GA5_6",
  dataset$rv2.lineage %in% "GA6" ~ "GA5_6",
  dataset$rv2.lineage %in% "CO1" ~ "CO1_2",
  dataset$rv2.lineage %in% "CO2" ~ "CO1_2",
  dataset$rv2.lineage %in% "GL1" ~ "GL1_2",
  dataset$rv2.lineage %in% "GL2" ~ "GL1_2",
  dataset$rv2.lineage %in% "GL3" ~ "GL3_4",
  dataset$rv2.lineage %in% "GL4" ~ "GL3_4",
  dataset$rv2.lineage %in% "GL5" ~ "GL5",
)

DefaultAssay(dataset) <- "peaks"
all.features <- StringToGRanges(rownames(dataset))

gene_id2name <- hash(rownames(dataset[['RNA']][[]]),dataset[['RNA']][[]][,1])
gene_name2id <- hash(dataset[['RNA']][[]][,1],rownames(dataset[['RNA']][[]]))
```

```{r Reading Tobias results and H12 metadata, eval=TRUE}
rV2.groups.tobias.h12.gr.dr <- get_BINDetect_snakemake_results(res_path="/Volumes/MyBookDuo/Data/TOBIAS_input_output/E12rV2_090224/TFBS/",parallel=T, HOCOMOCO=12,mc.cores = 10)

#H12.metadata <- qread(file="../analysis/H12_metadata_mod.qs")
#H12.metadata$TF.rep <- paste(H12.metadata$name,"_",H12.metadata$name,sep="")
#write_csv(H12.metadata, col_names = TRUE, file = "../metadata/H12.data.csv")
H12.metadata <- read_delim("../metadata/H12.data_INSM1_added.csv", col_names = TRUE, delim = ";")
```

```{r TRansform tobias gr to tb, eval=FALSE}
tobias.tb.list <- lapply(rV2.groups.tobias.h12.gr.dr, as_tibble)
tobias.tb <- do.call(rbind,tobias.tb.list)
tobias.tb$start <- tobias.tb$start+1 
qsave(tobias.tb, file = "../analysis/Tobias.rv2.h12.dr.tb_140524.qs",nthreads = cores)
rm(rV2.groups.tobias.h12.gr.dr)
gc()
```

```{r}
tobias.tb <- qread(file = "../analysis/Tobias.rv2.h12.dr.tb_140524.qs",nthreads = cores)
```

```{r}
# Select relevant columns
TFBS.pos.tb <- tobias.tb %>% dplyr::select(seqnames, start, end, TFBS_name)

# Create GRanges object from selected columns
TFBS.gr <- makeGRangesFromDataFrame(TFBS.pos.tb, keep.extra.columns = TRUE)

# Perform overlap merge
TFBS.to.features <- findOverlaps(TFBS.gr, all.features, type = "within")

# Extract matched ranges
query_hits <- queryHits(TFBS.to.features)
subject_hits <- subjectHits(TFBS.to.features)

# Convert to tibble and merge
TFBS.to.features.tb <- as_tibble(TFBS.gr[query_hits]) %>%
  mutate(features = GRangesToString(all.features[subject_hits]))

# Join the results back to the original tibble
tobias.tb.2 <- left_join(tobias.tb, TFBS.to.features.tb, by = c("seqnames", "start", "end", "TFBS_name"))

# Clean up
rm(TFBS.to.features.tb)
rm(tobias.tb)
gc()

qsave(tobias.tb.2, file = "../analysis/Tobias.rv2.h12.dr.tb_140524.2.qs",nthreads = cores)
```

```{r Finding TFBS to feature matches, eval=FALSE}
# TFBS.pos.tb <- tobias.tb %>% select(seqnames, start, end, TFBS_name)
# TFBS.to.features <- mergeByOverlaps(query = makeGRangesFromDataFrame(TFBS.pos.tb, keep.extra.columns = T), subject = all.features,type="within")
# 
# TFBS.to.features.tb <- cbind(as_tibble(TFBS.to.features$`makeGRangesFromDataFrame(TFBS.pos.tb, keep.extra.columns = T)`), features=GRangesToString(TFBS.to.features$all.features))
#                              
# tobias.tb.2 <- left_join(tobias.tb, select(TFBS.to.features.tb, seqnames, start, end, TFBS_name, features))
# rm(TFBS.to.features.tb)
# rm(tobias.tb)
# 
# qsave(tobias.tb.2, file = "../analysis/Tobias.rv2.h12.dr.tb_140524.2.qs",nthreads = cores)
```

```{r Connection to SQLite}
#con <- DBI::dbConnect(RSQLite::SQLite(), dbname = "~/Workspace/TOBIAS.dr.h12_140524.sqlite")
con.obj <- DBI::dbConnect(RSQLite::SQLite(), dbname = "~/Workspace/TOBIAS.dr.h12_140524.sqlite")
```

```{r Write gene.metadata into SQlite}
gene.metadata <- dataset[['RNA']][[]] %>% rownames_to_column("ensg_id") %>% rename("feature_symbol"="gene_name")
dbWriteTable(con.obj, "gene_metadata", gene.metadata, overwrite=TRUE)
dbExecute(con.obj, 'CREATE INDEX ensg_id3 ON gene_metadata (ensg_id);')
dbExecute(con.obj, 'CREATE INDEX gene_name3 ON gene_metadata (gene_name);')
```

```{r Write features table into SQLite, eval=FALSE}
features.tb <- as_tibble(all.features)
features.tb$feature <- paste(features.tb$seqnames,"-",features.tb$start,"-",features.tb$end,sep="")

dbWriteTable(con.obj, "feature", features.tb, overwrite=TRUE)
dbExecute(con.obj, 'CREATE INDEX features2 ON feature (feature);')
dbExecute(con.obj, 'CREATE INDEX seqnames2 ON feature (seqnames);')
dbExecute(con.obj, 'CREATE INDEX start2 ON feature (start);')
dbExecute(con.obj, 'CREATE INDEX end2 ON feature (end);')
```

```{r Write TOBIAS data into SQlite, eval=TRUE}
dbWriteTable(con.obj, "tobias", tobias.tb.2, overwrite=TRUE)
dbListTables(con.obj)
rm(tobias.tb.2)
gc()
```

```{r Build indeces, eval=TRUE}
dbExecute(con.obj, 'CREATE INDEX seqname 
ON tobias (seqnames);')

dbExecute(con.obj, 'CREATE INDEX position 
ON tobias (seqnames, start, end);')

dbExecute(con.obj, 'CREATE INDEX TFBS_name 
ON tobias (TFBS_name);')

dbExecute(con.obj, 'CREATE INDEX features 
ON tobias (features);')
```

```{r}
tobias.tm <- dbGetQuery(con.obj, 'SELECT TFBS_name FROM tobias')

tobias.tm <- left_join(tobias.tm, dplyr::select(H12.metadata, TF.rep, masterlist_info.tf,ensg_id), by=c("TFBS_name"="TF.rep")) %>% distinct()
colnames(tobias.tm) <- c("TFBS_name","masterlist_info_tf","ensg_id")

dbWriteTable(con.obj, "gene_name_tmp", tobias.tm)
dbExecute(con.obj, 'CREATE INDEX TFBS_name_2 
ON gene_name_tmp (TFBS_name);')

dbExecute(con.obj, 'ALTER TABLE tobias ADD COLUMN TF_gene_name TEXT;')
dbExecute(con.obj, 'ALTER TABLE tobias ADD COLUMN ensg_id TEXT;')

dbExecute(con.obj, '
UPDATE tobias
SET TF_gene_name = (
    SELECT masterlist_info_tf
    FROM gene_name_tmp
    WHERE gene_name_tmp.TFBS_name = tobias.TFBS_name
),
ensg_id = (
    SELECT ensg_id
    FROM gene_name_tmp
    WHERE gene_name_tmp.TFBS_name = tobias.TFBS_name
);
')

dbExecute(con.obj, 'DROP TABLE gene_name_tmp;')

dbExecute(con.obj, 'CREATE INDEX TF_gene_name ON tobias (TF_gene_name);')
dbExecute(con.obj, 'CREATE INDEX ensg_id ON tobias (ensg_id);')
gc()
```

<!-- ```{r Reading conservation data} -->
<!-- cons.gr <- import.bw(con="../metadata/mm10.60way.phastCons.bw",as="GRanges") -->
<!-- ``` -->

<!-- ```{r} -->
<!-- TFBS.loc <- dbGetQuery(con, 'SELECT seqnames, start, end, TFBS_name FROM tobias WHERE seqnames IN ("chr1","chr2","chr3","chr4","chr5","chr6","chr7","chr8","chr9","chr10","chr11","chr12","chr13","chr14","chr15","chr16","chr17","chr18","chr19","chrX","chrY");') -->
<!-- ``` -->

<!-- ```{r} -->
<!-- uniq.seq.names <- unique(pull(TFBS.loc,seqnames)) -->

<!-- TFBS.loc.cons.list <- mclapply(uniq.seq.names, function(seq.name){ -->
<!--   message_parallel(paste("Processing",seq.name,sep=" ")) -->
<!--   gc() -->
<!--   TFBS.tmp <- makeGRangesFromDataFrame(filter(TFBS.loc, seqnames==seq.name)) -->
<!--   cons.subset <- cons.gr[seqnames(cons.gr)==seq.name] -->
<!--   overlaps <- findOverlaps(query = cons.subset, subject = TFBS.tmp, type = "within") -->
<!--   TFBS.cons <- mergeByOverlaps(query = cons.subset, subject = TFBS.tmp, type="within") -->
<!--   mcols(TFBS.cons$TFBS.tmp)$score <- TFBS.cons$score -->
<!--   TFBS.cons.means <- as_tibble(TFBS.cons$TFBS.tmp %>% plyranges::group_by(start,end) %>% summarize(mean.cons=mean(score))) -->
<!--   TFBS.cons.means$seqnames <-seq.name -->
<!--   return(TFBS.cons.means) -->
<!-- }, mc.cores = 1) -->


<!-- TFBS.loc.cons.tb <- do.call(rbind,TFBS.loc.cons.list) -->
<!-- colnames(TFBS.loc.cons.tb) <- c("start","end","mean_cons","seqnames") -->
<!-- tobias.cons.tmp <- left_join(TFBS.loc, TFBS.loc.cons.tb, by=c("seqnames","start","end")) -->

<!-- dbWriteTable(con, "TFBS_pos_cons_tmp", tobias.cons.tmp, overwrite=TRUE) -->
<!-- dbExecute(con, 'CREATE INDEX TFBS_loc_2 -->
<!-- ON TFBS_pos_cons_tmp (seqnames, start, end);') -->

<!-- dbExecute(con, 'ALTER TABLE tobias ADD COLUMN mean_cons REAL;') -->

<!-- dbExecute(con, ' -->
<!-- UPDATE tobias -->
<!-- SET mean_cons = ( -->
<!--     SELECT mean_cons -->
<!--     FROM TFBS_pos_cons_tmp -->
<!--     WHERE TFBS_pos_cons_tmp.seqnames = tobias.seqnames AND TFBS_pos_cons_tmp.start = tobias.start AND TFBS_pos_cons_tmp.end = tobias.end -->
<!-- )') -->


<!-- # Not all TFBS get conservation score, is this becuase of the conservation source data?? -->

<!-- dbExecute(con, 'DROP TABLE TFBS_pos_cons_tmp;') -->
<!-- ``` -->

```{r}

# Function to load conservation data one chromosome at a time to manage memory use
import_bw_chunk <- function(chromosome) {
  gr <- GRanges(seqnames = chromosome, ranges = IRanges(start = 1, end = seqlengths(BSgenome.Mmusculus.UCSC.mm10)[chromosome]))
  import(con = "../metadata/mm10.60way.phastCons.bw", which = gr)
}

# Read TFBS locations from the database
TFBS.loc <- dbGetQuery(con.obj, 'SELECT seqnames, start, end, TFBS_name FROM tobias WHERE seqnames IN ("chr1","chr2","chr3","chr4","chr5","chr6","chr7","chr8","chr9","chr10","chr11","chr12","chr13","chr14","chr15","chr16","chr17","chr18","chr19","chrX","chrY");')

# Use data.table for efficient data manipulation
TFBS.loc <- as.data.table(TFBS.loc)
uniq.seq.names <- unique(TFBS.loc$seqnames)

# Function to process each chromosome
process_chromosome <- function(seq.name) {
  message_parallel(paste("Processing", seq.name))
  gc()

  # Load conservation data for the chromosome
  cons.gr <- import_bw_chunk(seq.name)
  if (length(cons.gr) == 0) return(NULL)

  # Subset TFBS for the chromosome
  TFBS.tmp <- TFBS.loc[seqnames == seq.name]
  if (nrow(TFBS.tmp) == 0) return(NULL)

  TFBS.gr <- makeGRangesFromDataFrame(TFBS.tmp)

  # Find overlaps
  overlaps <- findOverlaps(query = cons.gr, subject = TFBS.gr, type = "within")

  # Merge overlaps and compute mean conservation score
  if (length(overlaps) == 0) return(NULL)

  cons.subset <- cons.gr[queryHits(overlaps)]
  TFBS.subset <- TFBS.gr[subjectHits(overlaps)]
  TFBS.subset$score <- cons.subset$score

  TFBS.cons.means <- as_tibble(TFBS.subset %>% plyranges::group_by(start, end) %>% summarize(mean.cons = mean(score)))
  TFBS.cons.means$seqnames <- seq.name

  return(TFBS.cons.means)
}

# Process each chromosome in parallel
TFBS.loc.cons.list <- mclapply(uniq.seq.names, process_chromosome, mc.cores = 2)

# Filter out NULL results
TFBS.loc.cons.list <- Filter(Negate(is.null), TFBS.loc.cons.list)

# Combine results into one table
TFBS.loc.cons.tb <- rbindlist(TFBS.loc.cons.list, fill = TRUE)
colnames(TFBS.loc.cons.tb) <- c("start", "end", "mean_cons", "seqnames")

# Merge results back to original TFBS locations
tobias.cons.tmp <- merge(TFBS.loc, TFBS.loc.cons.tb, by = c("seqnames", "start", "end"), all.x = TRUE)

# Write results back to the database
dbWriteTable(con.obj, "TFBS_pos_cons_tmp", tobias.cons.tmp, overwrite = TRUE)
dbExecute(con.obj, 'CREATE INDEX TFBS_loc_2 ON TFBS_pos_cons_tmp (seqnames, start, end);')
dbExecute(con.obj, 'ALTER TABLE tobias ADD COLUMN mean_cons REAL;')

dbExecute(con.obj, '
UPDATE tobias
SET mean_cons = (
    SELECT mean_cons
    FROM TFBS_pos_cons_tmp
    WHERE TFBS_pos_cons_tmp.seqnames = tobias.seqnames AND TFBS_pos_cons_tmp.start = tobias.start AND TFBS_pos_cons_tmp.end = tobias.end
)')

dbExecute(con.obj, 'DROP TABLE TFBS_pos_cons_tmp;')

# Cleanup
gc()
```

```{r, eval=TRUE}
# Initialize a variable to store problematic groups
problematic_groups <- list()

# Define a function to calculate the weighted mean for each group
calculate_weighted_mean <- function(data) {
  TFBS_name <- unique(data$TFBS_name)
  if (length(TFBS_name) != 1) {
    stop("Each group should have exactly one TFB_name.")
  }
  weights <- positional.mean.weights[[TFBS_name]]
  if (is.null(weights)) {
    stop(paste("No weights found for TFB_name:", TFBS_name))
  }
  if (length(weights) != nrow(data)) {
    # Store information about the problematic group
    problematic_groups <<- append(problematic_groups, list(tibble(start = unique(data$start), end = unique(data$end), TFBS_name = TFBS_name, difference = length(weights)- nrow(data))))
    # Return NA
    mean.cons <- NA
  } else {
    # Calculate weighted mean
    mean.cons <- weighted.mean(data$score, weights)
  }
  tibble(start = unique(data$start), end = unique(data$end), TFBS_name = TFBS_name, mean.cons = mean.cons)
}


uniq.seq.names <- unique(pull(TFBS.loc,seqnames))

TFBS.loc.cons.list <- mclapply(uniq.seq.names, function(seq.name){
  message_parallel(paste("Processing",seq.name,sep=" "))
  gc()
  TFBS.tmp <- makeGRangesFromDataFrame(dplyr::filter(TFBS.loc, seqnames==seq.name), keep.extra.columns = T)
  cons.subset <- import_bw_chunk(seq.name)
  
  # Split TFBS.tmp into single-base intervals
  TFBS.tmp.split <- unlist(tile(TFBS.tmp, width=1))

  # Replicate metadata to each single-base interval
  metadata <- as.data.frame(mcols(TFBS.tmp))
  metadata_rep <- metadata[rep(1:nrow(metadata), lengths(tile(TFBS.tmp, width=1))), ]
  mcols(TFBS.tmp.split) <- metadata_rep
  
  # Find overlaps between single-base intervals and cons.subset
  overlaps <- findOverlaps(query = cons.subset, subject = TFBS.tmp.split)

  # Create a data frame from TFBS.tmp.split
  TFBS.df <- as.data.frame(TFBS.tmp.split)
  colnames(TFBS.df)[colnames(TFBS.df) == "X"] <- "TFBS_name"
  
  # Initialize the score column with NA
  TFBS.df$score <- NA

  # Get the indices of the overlapping regions
  query_hits <- queryHits(overlaps)
  subject_hits <- subjectHits(overlaps)

  # Copy the score from cons.subset to TFBS.df
  TFBS.df$score[subject_hits] <- mcols(cons.subset)$score[query_hits]

  # Create a grouping variable to identify consecutive ranges
  TFBS.df <- TFBS.df %>%
  arrange(TFBS_name, start, end) %>%
  mutate(group = cumsum(c(1, diff(start) != 1 | diff(as.numeric(factor(TFBS_name))) != 0)))
  
# TFBS.df <- TFBS.df %>%
#   arrange(TFBS_name, start) %>%
#   mutate(is_consecutive = (start == dplyr::lag(end, default = dplyr::first(start))) & (TFBS_name == dplyr::lag(TFBS_name, default = dplyr::first(TFBS_name))), group = cumsum(!is_consecutive)) %>%
#   dplyr::select(-is_consecutive)

  # Update each row within the group to have the smallest start and largest end
  TFBS.df <- TFBS.df %>%
  group_by(group, TFBS_name) %>%
  mutate(start = min(start), end = max(end)) %>%
  ungroup() %>%
  dplyr::select(-group)  # Remove the temporary group column

  TFBS.cons.means <- TFBS.df %>% group_by(start,end,TFBS_name) %>% group_split() %>%
  map_dfr(~ calculate_weighted_mean(.x))
  TFBS.cons.means$seqnames <-seq.name
  return(TFBS.cons.means)
}, mc.cores = 2)

TFBS.loc.cons.tb <- do.call(rbind,TFBS.loc.cons.list)
colnames(TFBS.loc.cons.tb) <- c("start","end","TFBS_name","w.mean_cons","seqnames")
tobias.cons.tmp <- left_join(TFBS.loc, TFBS.loc.cons.tb, by=c("seqnames","start","end","TFBS_name"))

dbWriteTable(con, "TFBS_pos_cons_tmp", tobias.cons.tmp, overwrite=TRUE)
dbExecute(con, 'CREATE INDEX TFBS_loc_2
ON TFBS_pos_cons_tmp (seqnames, start, end);')

dbExecute(con, 'ALTER TABLE tobias ADD COLUMN w_mean_cons REAL;')

dbExecute(con, '
UPDATE tobias
SET w_mean_cons = (
    SELECT mean_cons
    FROM TFBS_pos_cons_tmp
    WHERE TFBS_pos_cons_tmp.seqnames = tobias.seqnames AND TFBS_pos_cons_tmp.start = tobias.start AND TFBS_pos_cons_tmp.end = tobias.end
)')

dbExecute(con, 'DROP TABLE TFBS_pos_cons_tmp;')
```

# Calculate expression and accessibility information into the database

```{r Calculate and upload average gene expression data per cell group into separate table}
ensg_ids <- dbGetQuery(con, 'SELECT DISTINCT ensg_id FROM tobias;')[,1]

TF.expression.data.avg2 <- AverageExpression(dataset, assays = "RNA", features = ensg_ids, group.by = "rv2.lineage_re", layer = "data")[[1]]

dbWriteTable(con, "exp", as.data.frame(TF.expression.data.avg2) %>% rownames_to_column("ensg_id") %>% as_tibble(), overwrite=TRUE)

dbExecute(con, 'CREATE INDEX ensg_ids_2 ON exp (ensg_id);')
```

```{r Calculate and upload z-score normalized gene expression averages per TF gene per cell group into separate table}
ensg_ids <- dbGetQuery(con, 'SELECT DISTINCT ensg_id FROM tobias;')[,1]

DefaultAssay(dataset) <- "RNA"
TF.expression.data <- FetchData(object=dataset, assays = "RNA", vars = c(ensg_ids,"rv2.lineage_re"))
TF.expression.data.mat <- as.matrix(expm1(as_tibble(TF.expression.data) %>% select(!starts_with("rv"))))
TF.expression.data.mat <- as_tibble(t(scale(t(TF.expression.data.mat))))
TF.expression.data.mat$rv2.lineage_re <- TF.expression.data$rv2.lineage_re
TF.expression.data.mat <- pivot_longer(TF.expression.data.mat, cols = !starts_with("rv"))

TF.expr.scaled <- TF.expression.data.mat %>% group_by(rv2.lineage_re, name) %>% summarise(avg.exp=mean(value,na.rm=T)) %>% pivot_wider(values_from = avg.exp, names_from = rv2.lineage_re)

names(TF.expr.scaled)[1] <- "ensg_id"

dbWriteTable(con, "exp_scaled", TF.expr.scaled, overwrite=TRUE)

dbExecute(con, 'CREATE INDEX ensg_ids_3 ON exp_scaled (ensg_id);')
```

```{r Calculate and upload feature accessibility data per feature per cell group into separate table }
features <- dbGetQuery(con, 'SELECT DISTINCT features FROM tobias;')[,1]

acc.avg.data <- AverageExpression(dataset, assays = "peaks", features = features, group.by = "rv2.lineage_re")[[1]]

dbWriteTable(con, "acc", as.data.frame(acc.avg.data) %>% rownames_to_column("features") %>% as_tibble(), overwrite=TRUE)

dbExecute(con, 'CREATE INDEX features_2 ON acc (features);')
```

```{r Additional corrections to TF_gene_name field}
dbExecute(con, "UPDATE tobias
SET TF_gene_name = 'NGN1'
WHERE TF_gene_name LIKE '1,0%NGN';")

dbExecute(con, "UPDATE tobias
SET TF_gene_name = 'NGN2'
WHERE TF_gene_name LIKE '2,0%NGN';")

dbExecute(con, "UPDATE tobias
SET TF_gene_name = 'MAD4'
WHERE TF_gene_name LIKE '4,0%MAD';")
```

```{r Calculating LinkPeaks within TADs}
E12_rV2 <- qread(file = "../scATAC_data/nmm_rV2_subset_relabeled_031023_links.qs", nthreads = cores)

DefaultAssay(E12_rV2) <- "peaks"

Links(E12_rV2) <- GenomicRanges::GRanges()

mm10.v79.genome.GR <- toGRanges(
  EnsDb.Mmusculus.v79,
  feature = c("gene", "transcript", "exon", "disjointExons")
)

mm10.v79.genome.GR$gene_id <- names(mm10.v79.genome.GR)

DefaultAssay(E12_rV2) <- "RNA"

gene_ids <- unique(intersect(names(mm10.v79.genome.GR),rownames(E12_rV2)))

#the information about TAD areas - https://cb.csail.mit.edu/cb/tadmap/
TAD.map <- read_table("../metadata/cb.csail.mit.edu_cb_tadmap_TADMap_scaffold_mm.bed.txt", col_names = c("seqnames", "start", "end")) %>% GRanges()

#Function
links.within.TADs <- mclapply(gene_ids, function(idx){
  message_parallel(idx)
  con.obj <- DBI::dbConnect(RSQLite::SQLite(), dbname = "~/Workspace/TOBIAS.dr.h12_140524.sqlite")
  
  #first we find the TAD - topologically associated domain - for gene in a question
  gene.range <- mm10.v79.genome.GR[which(names(mm10.v79.genome.GR) == idx)]

  TAD.overlap <-plyranges::filter_by_overlaps(TAD.map,gene.range)
  tryCatch({
    Link.Seurat <- LinkPeaks(object = E12_rV2, peak.assay = "peaks", expression.assay = "RNA", genes.use = idx, gene.id = T, distance = width(TAD.overlap), gene.coords = mm10.v79.genome.GR,  peak.slot = "counts", expression.slot = "data", method = "pearson")
  
    links.tb <- as_tibble(Link.Seurat@assays$peaks@links) %>% rename("peak"="feature") %>% rename("gene"="ensg_id")
    success <- FALSE
    while(!success & base::exists("links.tb")) {
      tryCatch({
       dbWriteTable(con.obj, "links", links.tb, overwrite=FALSE, append=TRUE)
        success<-TRUE
      }, error = function(e) {
        Sys.sleep(0.25)
      })
    }
    },
  error = function(e) {
    cat("An error occurred:", e$message, "\n")
    },
  warning = function(w) {
    cat("A warning occurred:", w$message, "\n")
  })
  # Handle warning if necessary)
  DBI::dbDisconnect(con.obj)
  #return(links)
}, mc.cores = cores)

dbExecute(con, 'CREATE INDEX ensg_id5 ON links (ensg_id);')
dbExecute(con, 'CREATE INDEX feature4 ON links (feature);')
dbExecute(con, 'CREATE INDEX zscore1 ON links (zscore);')
dbExecute(con, 'CREATE INDEX links_pvalue ON links (pvalue);')
```

```{r}
links.within.TADs <- qread("../analysis/links.within.TADs.qs")


check_identity <- function(tibble_in_list) {
  any(pmap_lgl(B, ~ identical(tibble_in_list, tibble(...))))
}

DefaultAssay(E12_rV2) <- "peaks"
B <- as_tibble(Links(E12_rV2))


identical_elements <- map_lgl(links.within.TADs, check_identity)


links.within.TADs.tb <- do.call(rbind,links.within.TADs) %>% dplyr::filter(!is.na(seqnames))

con <- DBI::dbConnect(RSQLite::SQLite(), dbname = "~/Workspace/TOBIAS.dr.h12_110424.sqlite")
success <- dbWriteTable(con, "links", links.within.TADs.tb, overwrite=TRUE)

dbExecute(con, 'CREATE INDEX ensg_id5 ON links (ensg_id);')
dbExecute(con, 'CREATE INDEX feature4 ON links (feature);')
dbExecute(con, 'CREATE INDEX zscore1 ON links (zscore);')
dbExecute(con, 'CREATE INDEX links_pvalue ON links (pvalue);')

DBI::dbDisconnect(con)
```


```{r C&T data import}
consensus.beds.path <- list.files(path="/Volumes/MyBookDuo/Data/Cut_Tag/out_180424/180424_2re_thr001/03_peak_calling/05_consensus_peaks/", pattern = "*.awk.bed", full.names = T)

consensus.beds <- lapply(consensus.beds.path, function(path){
  tmp.1 <- read_delim(file = path, col_names = c("chr","start","end","start_merged","end_merged","total_signals","max_signals","max_signal_regions","sample_names","consensus_replicate_count"))
  if (nrow(tmp.1)>0){
  tmp.1$target_gene_name <- str_extract(string=tmp.1$sample_names, pattern = "(?<=_)[^_]+(?=_)")
  return(tmp.1)
  } else {
    return(NA)
  }
  })

consensus.beds.tb <- do.call(rbind,consensus.beds)
consensus.beds.tb <- consensus.beds.tb %>% mutate(row_id = row_number()) 

# Normalize the data (in SQL sense)
normalized_data <- consensus.beds.tb %>%
  # Create an index to keep track of the original row positions
  # Expand the rows based on the comma-separated values
  separate_rows(total_signals, max_signals, max_signal_regions,sample_names, sep = ",") %>%
  # Group by the original row index to ensure correct order
  group_by(row_id) %>%
  # Create a new ID to ensure uniqueness
  mutate(normalized_id = row_number()) %>%
  ungroup()

normalized_data<-normalized_data[!is.na(normalized_data$chr),]
```

```{r}
ct.gr <- makeGRangesFromDataFrame(normalized_data,na.rm=T, keep.extra.columns = T)
feat.gr <- all.features

# Assuming ct.gr and feat.gr are already defined GRanges objects
# Find overlaps
overlaps <- findOverlaps(ct.gr, feat.gr)

# Assuming 'A' is your original tibble that corresponds to ct.gr
# Let's add an identifier to 'A' for the linkage
normalized_data <- normalized_data %>% mutate(row_id = row_number())

# Extract overlapping information with a new 'feature' column that combines 'chr', 'start', 'end'
overlap_info <- tibble(
  row_id = queryHits(overlaps),
  feature = paste(seqnames(feat.gr)[subjectHits(overlaps)], 
                  start(feat.gr)[subjectHits(overlaps)], 
                  end(feat.gr)[subjectHits(overlaps)], 
                  sep = "-")
)

normalized_data_expanded <- normalized_data %>%
  right_join(overlap_info, by = "row_id")

normalized_data_expanded <- normalized_data_expanded %>% mutate(start=as.integer(start), end=as.integer(end), total_signals=as.numeric(total_signals), max_signals=as.numeric(max_signals), consensus_replicate_count=as.integer(consensus_replicate_count))

```

```{r}
dbWriteTable(con, "CT_data", normalized_data_expanded, overwrite=TRUE)
dbExecute(con, 'CREATE INDEX CT_data_feature ON CT_data (feature);')
dbExecute(con, 'CREATE INDEX CT_data_max_signals ON CT_data (max_signals);')
dbExecute(con, 'CREATE INDEX CT_data_target_gene_name ON CT_data (target_gene_name);')
```


```{r}
DefaultAssay(dataset) <- "peaks"
acc.data.matrix <- FetchData(dataset, vars = rownames(dataset))
zero.test <- apply(acc.data.matrix,2,function(col){!all(col==0)})
acc.data.matrix<- acc.data.matrix[,zero.test]
DefaultAssay(dataset) <- "RNA"

TF_ensg_ids <- unique(dbGetQuery(con, 'SELECT ensg_id FROM tobias;')[,1])
DBI::dbDisconnect(con)

mclapply(TF_ensg_ids, function(ensg_id){
  tryCatch({
    exp.data.matrix <- FetchData(dataset, vars = ensg_id)
    if (!all(exp.data.matrix[,1]==0)){
    #message_parallel(paste("Calculating gene ",ensg_id))
    test.res <- na.omit(cor(exp.data.matrix,acc.data.matrix, method = "spearman", use="pairwise.complete.obs"))
    data.to.db <- tibble(ensg_id=rownames(test.res),feature=colnames(test.res),cor=test.res[1,])
    
    success <- FALSE
    con.obj <- DBI::dbConnect(RSQLite::SQLite(), dbname = "~/Workspace/TOBIAS.dr.h12_130324.sqlite")
    while(!success) {
      tryCatch({
        success <- dbWriteTable(con.obj, "gene2feat_cor", data.to.db, overwrite=FALSE, append=TRUE)
        DBI::dbDisconnect(con.obj)
      }, error = function(e) {
        Sys.sleep(0.25)
      }, warning = function(e) {
        e
      })
    }
    }
    
    
  }, error=function(cond){
    cond
  },warning=function(cond){
    cond
  })
  
},mc.cores=3)
dbExecute(con, 'CREATE INDEX gene2feat_cor_ensg_id ON gene2feat_cor (ensg_id);')
dbExecute(con, 'CREATE INDEX gene2feat_cor_cor ON gene2feat_cor (cor);')
dbExecute(con, 'CREATE INDEX gene2feat_cor_feature ON gene2feat_cor (feature);')
```


```{r Finding consequent motif areas}
tobias.table <- tbl(con, "tobias")
exp.table <- tbl(con, "exp")
acc.table <- tbl(con, "acc")
table.tmp.1 <- tobias.table %>% left_join(exp.table) %>% left_join(acc.table, by=c("features"="features")) %>% dplyr::filter(mean_cons>0.5)
table.tmp.2 <- table.tmp.1 %>% collect()

acc.thr <- quantile(acc.table %>% dplyr::select(!starts_with("features")) %>% pull(),.25)
mean_cons_thr<-0.5

table.tmp.2 <- table.tmp.2 %>% dplyr::filter((abs(PRO1_2.x)>1.2 | abs(CO1_2.x)>1.2 | abs(GA1_2.x)>1.2 | abs(GL1_2.x)>1.2) & (abs(PRO1_2.y)>acc.thr | abs(CO1_2.y)>acc.thr | abs(GA1_2.y)>acc.thr | abs(GL1_2.y)>acc.thr) & (PRO1_2_bound==1 | CO1_2_bound==1 | GA1_2_bound==1 | GL1_2_bound==1) & mean_cons>mean_cons_thr) %>% arrange(start)

grB <- makeGRangesFromDataFrame(dplyr::select(table.tmp.2, seqnames, start, end, TFBS_name), keep.extra.columns = T)

reduced_grB_with_map <- reduce(grB, min.gapwidth=0L,with.revmap = TRUE)


# Step 2: Concatenate metadata based on the revmap information
concatenated_metadata <- mclapply(reduced_grB_with_map$revmap, function(indices) {
  if (length(indices) > 0) {
    meta_values <- mcols(grB)[indices, ]
    paste(unique(na.omit(meta_values)), collapse = "; ")
  } else {
    ""
  }
}, mc.cores = 10)

mcols(reduced_grB_with_map)$concatenated_metadata <- concatenated_metadata

plyranges::filter_by_overlaps(reduced_grB_with_map,StringToGRanges("chr4-114432894-115134633"))
mcols(plyranges::filter_by_overlaps(reduced_grB_with_map,StringToGRanges("chr4-114432894-115134633")))$concatenated_metadata

saveRDS(reduced_grB_with_map,"../analysis/TFBS_reduced_positions_120324.Rds")
```

```{r Calculating TFBS binding probability background}
genes_TF_count <- dbGetQuery(con, 'SELECT li.ensg_id,
       tb.TF_gene_name,
       COUNT(tb.TF_gene_name) AS count
FROM links AS li
JOIN tobias AS tb ON tb.features = li.feature
WHERE li.zscore > 2 AND tb.mean_cons>0.5
GROUP BY li.ensg_id, tb.TF_gene_name;')
```

```{r}
genes_TF_count.wide <- pivot_wider(genes_TF_count,names_from = ensg_id, values_from = count)
#genes_TF_count.wide[is.na(genes_TF_count.wide)] <-0
genes_TF_count.wide.mat <- as.matrix(genes_TF_count.wide[,-1])
rownames(genes_TF_count.wide.mat) <- genes_TF_count.wide$TF_gene_name

# Parameters for the sigmoid function
a <- .15
b <- 0

# Calculate binding_probs using a sigmoid function
binding_probs <- 1 / (1 + exp(-(a * genes_TF_count.wide.mat + b)))

mean_binding_probs <- apply(binding_probs, 1, function(x) mean(x,na.rm=T))

lambda <- sum(mean_binding_probs)

C <- 3
prob_exact <- dpois(C, lambda)
```

